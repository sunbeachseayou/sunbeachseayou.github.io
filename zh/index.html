<!DOCTYPE html><html lang="zh-Hans" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  
  
  <meta name="generator" content="Wowchemy 4.8.0 for Hugo">
  

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="傅剑">

  
  
  
    
  
  <meta name="description" content="机器人工程系主任">

  
  <link rel="alternate" hreflang="en" href="/en/">
  
  <link rel="alternate" hreflang="zh-Hans" href="/zh/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js" integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.css">

  




  


  
  
  <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
  

  
  <link rel="alternate" href="/zh/index.xml" type="application/rss+xml" title="傅剑实验室主页">
  

  <link rel="manifest" href="/zh/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="/zh/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="傅剑实验室主页">
  <meta property="og:url" content="/zh/">
  <meta property="og:title" content="傅剑实验室主页">
  <meta property="og:description" content="机器人工程系主任"><meta property="og:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png">
  <meta property="twitter:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="zh-Hans">
  
    <meta property="og:updated_time" content="2020-09-15T21:25:49&#43;08:00">
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite","url": "/"
}
</script>


  


  


  





  <title>傅剑实验室主页</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  
  
  
  
    <script>const isSiteThemeDark = false;</script>
  
  
  <script src="/js/load-theme.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>搜索</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/zh/">傅剑实验室主页</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="切换导航">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/zh/">傅剑实验室主页</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#about" data-target="#about"><span>主页</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#posts" data-target="#posts"><span>祝贺</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#publications" data-target="#publications"><span>近期文章</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#publications1" data-target="#publications1"><span>实验室访问/合作发表</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#people" data-target="#people"><span>团队成员</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#projects" data-target="#projects"><span>近期项目</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#CurriculumVitae" data-target="#CurriculumVitae"><span>简历</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#vedios" data-target="#vedios"><span>视频墙</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#photo" data-target="#photo"><span>照片墙</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#contact" data-target="#contact"><span>联系我</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      

      
      

      
      <li class="nav-item dropdown i18n-dropdown">
        <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-globe mr-1" aria-hidden="true"></i><span class="d-none d-lg-inline">中文 (简体)</span></a>
        <div class="dropdown-menu">
          <div class="dropdown-item dropdown-item-active">
            <span>中文 (简体)</span>
          </div>
          
          <a class="dropdown-item" href="/en/" data-target="/en/">
            <span>English</span>
          </a>
          
        </div>
      </li>
      

    </ul>

  </div>
</nav>



  











  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="about" class="home-section wg-about   "  >
    <div class="container">
      




  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle" src="/zh/author/%E5%82%85%E5%89%91/avatar_hu10142293f5aa0a3e5c0500d8d194dbe9_311336_270x270_fill_q90_lanczos_center.jpg" alt="傅剑">
      

      <div class="portrait-title">
        <h2>傅剑</h2>
        <h3>机器人工程系主任</h3>

        
        <h3>
          
          <span>武汉理工大学</span>
          
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    <h1>Biography</h1>

    <!-- Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate. -->
<!-- (1999)MSc in Master of Computer Application.Huazhong University of Science. 

(2006)Phd in Control Theory and ControlEngineering. Universityof Science and Technology Beijing.

(2009-2010)Visiting scholar in Stevens Institute of Technology and University ofRhode Island. 

Members of IEEE ADPRL TC(Adaptive Dynamic Programmingand Reinforcement Learning Technical Committee).

More than 20 papershave been published by SCI and EI in important journals andconferences at home and abroad. -->


    <div class="row">

      
      <div class="col-md-5">
        <h3>研究领域</h3>
        <ul class="ul-interests">
          
          <li>具身智能机器人/共融机器人</li>
          
          <li>认知与神经科学启发的人工智能</li>
          
          <li>物理信息系统</li>
          
          <li>AloT和移动互联网</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>教育经历</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">控制理论与控制工程博士, 2006</p>
              <p class="institution">北京科技大学</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">计算机应用硕士, 1999</p>
              <p class="institution">华中理工大学（华中科技大学）</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="posts" class="home-section wg-pages   "  >
    <div class="container">
      








  
























  





  




<div class="row ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>祝贺</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">

    <!-- _**Congratulation**_

Jian Fu receives CNSF grant (general program) titled as "study on motor skill acquistion
and execution for the coordination of human-robot collaboration".

_**Congratulation**_

Sun Junwei, 2017 graduate student, received an offer from jingdong research and development in shenzhen

Wang Kaiyuan, 2017 graduate student, received an offer from HIK VISION in Nanjing

Li Yuanyuan, 2017 graduate student, received an offer from WINGTECH in Shanghai

Du Yucheng, 2017 graduate student, received an offer from electric of ShangNeng in Wuxi

Chen Siming, 2017 graduate student, received an offer from iFLYTEK in Wuhan

_**Congratulation**_

Sun Junwei, 2017 graduate student, received an offer from jingdong research and development in shenzhen

Wang Kaiyuan, 2017 graduate student, received an offer from HIK VISION in Nanjing

Li Yuanyuan, 2017 graduate student, received an offer from WINGTECH in Shanghai

Du Yucheng, 2017 graduate student, received an offer from electric of ShangNeng in Wuxi

Chen Siming, 2017 graduate student, received an offer from iFLYTEK in Wuhan -->
<p><em><strong>Congratulation</strong></em></p>
<p>祝贺  实验室博士生申思远的论文“Rotational Impedance Formulation in a Unified Viewpoint of Lie Algebra” 被 IEEE Robotics and Automation Letters录用！</p>
<p>祝贺  实验室访问学生傅宇翔的论文“MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation Distillation” 被 CVPR 2025 录用！</p>
<p>傅剑“面向人机合作协同的机器人运动技能获取和执行研究”获得国家自然科学基金面上项目资助！</p>
<p><em><strong>Congratulation</strong></em></p>
<p>马寒戈，2025届研究生，华为上海录用</p>
<p>徐梦辉，2025届研究生，华为上海录用</p>
<p>叶小蝶，2025届研究生，绵阳长虹智慧显示录用</p>
<p>黄天辰，2025届研究生，广州众山精密科技有限公司录用</p>
<p>陈世翰，2025届研究生，武汉航达航空科技发展有限公司录用</p>
<p>杨竹，2024届研究生，宁德时代宁德录用</p>
<p>李小龙，2024届研究生，华为武汉录用</p>
<p>王竞耕，2024届研究生，交通银行武汉录用</p>
<p>赵鹏宇，2024届研究生，零跑杭州录用</p>
<p>王南，2024届研究生，零跑杭州录用</p>
<p>周璇，2024届研究生，京东方合肥录用</p>
<p>钟亚东，2023届研究生，华为成都录用</p>
<p>杨峰，2023届研究生，中兴长沙录用</p>
<p>王聿才，2023届研究生，比亚迪合肥录用</p>
<p>刘若拙，2022届研究生，网易杭州录用</p>
<p>李兴强，2022届研究生，华为深圳录用</p>
<p>胡立志，2022届研究生，华为武汉录用</p>
<p>李聪，2021届研究生，中兴武汉录用</p>
<p>杜瑾瑜，2021届研究生，华为南研所录用</p>
<p>滕翔，2020届研究生，华为武汉录用</p>
<p>王超奇，2020届研究生，华为武汉录用</p>
<p>耿惠莉，2020届研究生，中国电子系统技术有限公司录用</p>
<p>张洋，2019届研究生，高德红外武汉录用</p>
<p>杭亦文，2019届研究生，武汉理工大学自动化学院录用</p>
<p>秦亘，2019届研究生，华为武汉录用</p>
<p>夏聪，2019届研究生，中兴通讯武汉录用</p>
<p>申思远，2019届研究生，海康威视武汉录用</p>
<p>刘冰，2018届研究生，中兴通讯深圳录用</p>
<p>魏达，2018届研究生，小红书武汉录用</p>
<p>孙俊威, 2017届研究生，深圳京东研发公司录用</p>
<p>王开元, 2017届研究生，南京海康威视录用</p>
<p>李媛媛, 2017年研究生，上海闻泰科技录用</p>
<p>杜宇澄, 2017届研究生，无锡上能电气有限公司录用</p>
<p>陈思明, 2017届研究生，科大讯飞武汉分公司录用</p>


    

    
    
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="publications" class="home-section wg-pages   "  >
    <div class="container">
      








  
























  





  




<div class="row ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>近期文章</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">

    <h4 id="1-rotational-impedance-formulation-in-a-unified-viewpoint-of-lie-algebrahttpsieeexploreieeeorgdocument10896789">1. <a href="https://ieeexplore.ieee.org/document/10896789" target="_blank" rel="noopener">Rotational Impedance Formulation in a Unified Viewpoint of Lie Algebra</a></h4>
<p>Jian Fu; Siyuan Shen; Yuxiang Fu; Kui Xiang</p>
<p>IEEE Robotics and Automation Letters</p>
<details>
    <summary>Abstract</summary>
Impedance control is essential in robotic manipulation tasks involving unpredictable interactions with the environment, as it ensures safety and stability during contact. While the concept of translational impedance is consistently understood, rotational impedance exhibits varied forms in scientific literature. This paper seeks to elucidate the fundamental nature of rotational impedance and presents a comprehensive, unified framework for formulating rotational impedance using Lie algebra and Noether's theorem. This approach facilitates the derivation of the various expressions of rotational impedance observed in the field. We utilized quaternions and rotation matrices to represent rotational motion within our proposed framework to ensure theoretical validity. This approach yielded a rotational impedance expression that aligns with existing literature. For empirical verification, we have conducted both simulated experiments using robots and actual trials on a UR5 robot. These assessments demonstrated the expected dynamic responses along all axes. These results showcase the efficacy and broad applicability of our approach.
</details>
<h4 id="2-a-promps-based-framework-for-robot-variable-impedance-skill-acquisitionhttpsieeexploreieeeorgabstractdocument10649700">2. <a href="https://ieeexplore.ieee.org/abstract/document/10649700" target="_blank" rel="noopener">A ProMPs-Based Framework for Robot Variable Impedance Skill Acquisition</a></h4>
<p>Jian Fu; Xiaodie Ye</p>
<p>2024 International Symposium on Intelligent Robotics and Systems (ISoIRS)</p>
<details>    
    <summary>Abstract</summary>
Robustness and adaptability are key requirements for robots to interact with the physical environment, and impedance/admittance control play an important role in solving this problem. The robot learning of the variable impedance strategy based on dual Dynamic movement primitives (DMPs) has achieved good results; however, the single demonstration limitation inherent in DMPs makes it necessary to handcraft routine multiple demonstrations, inevitably incorporating personal preferences. We propose a framework based on probabilistic movement primitives (ProMPs) to address this problem in a data-driven manner. Its strategy representation in probabilistic form captures the whole information from human experts’ demonstrations in an objective manner rather than a subjective one. In addition, we have added critical moment points and endpoint moment-over-point constraints to the contours of the strategy expressions for position and stiffness, thus alleviating the problem of large endpoint deviations that has been a problem with conventional ProMPs. In this way, both flexibility of learning and precision of implementation in variable impedance skill transfer can be guaranteed. Finally, simulation experiments demonstrate the effectiveness and scalability of our proposed method.
</details>
<h4 id="3-adversarial-domain-generalization-with-mixstylehttpsieeexploreieeeorgdocument9959388">3. <a href="https://ieeexplore.ieee.org/document/9959388" target="_blank" rel="noopener">Adversarial Domain Generalization with MixStyle</a></h4>
<p>Jian Fu and Yadong Zhong and Feng Yang</p>
<p>International Conference on Advanced Robotics and Mechatronics (ICARM)</p>
<details>
    <summary>Abstract</summary>
The performance of deep neural networks deteriorates when the domain representing the underlying data distribution changes during training and testing. Domain generalization expects learning from multiple source domains to improve generalization to never-before-seen target domains. We propose hybrid domain generalization using source domain and multiple latent domains as a new research scenario, and we attempt to train a generalization model that self-generates latent domain labels. In order to solve this scenario, we use the MixStyle to generate latent domain samples and assume that the styles of the samples are closely related to their domains. Therefore, we propose that GMM cluster latent domains according to style features and iteratively assign pseudo domain labels before introducing them into adversarial training. By using image style features, Our proposed method successfully synthesizes latent domains and achieves adversarial domain generalization without latent domain labels. Meanwhile, considering that the original domain labels are underutilized, this method introduces an auxiliary feature extractor to improve the performance of the model. Experiments demonstrate that our method has excellent generalization performance and outperforms classical domain generalization methods.
</details>
<h4 id="4-online-static-obstacle-avoidance-and-offline-static-obstacle-avoidance-framework-based-on-interaction-probabilistic-movement-primitiveshttpslinkspringercomchapter101007978-981-99-2789-0_30">4. <a href="https://link.springer.com/chapter/10.1007/978-981-99-2789-0_30" target="_blank" rel="noopener">Online Static Obstacle Avoidance and Offline Static Obstacle Avoidance Framework Based on Interaction Probabilistic Movement Primitives</a></h4>
<p>Jian Fu, Feng Yang, Yadong Zhong &amp; Zhu Yang</p>
<p>School of Automation, Wuhan University of Technology, Wuhan 430070, China</p>
<details>
	<summary>Abstract</summary>
How to make robots self-adaptive to obstacle avoidance in the process of human-robot collaboration is one of the challenges in the community. In an actual environment, robots often encounter unanticipated obstacles that make it difficult to complete a task. So we in this paper proposed an obstacle avoidance framework based on Interaction Probabilistic Movement Primitives (iProMP), which combines online static obstacle avoidance with offline static obstacle avoidance. For unanticipated obstacles in human-robot collaboration, we find obstacle avoidance trajectories by solving the Lagrange equation, and then the product of Gaussian distribution is used to fuse the two iProMP trajectories to smoothly switch from the original trajectory to the obstacle avoidance trajectory to achieve fast online static obstacle avoidance. However, the obstacle avoidance trajectory is not optimal. When human-robot collaboration is over, the obstacle is usually not immediately cleared, and the unanticipated obstacles become the anticipated obstacles. In order to obtain a better obstacle avoidance trajectory, Path Integral Policy Improvement with Covariance Matrix Adaptation algorithm is used to train the demonstration trajectories to obtain new iProMP parameters, using the new parameters of human-robot cooperation to realize offline static obstacle avoidance. Experimental results based on two-dimensional trajectory obstacle avoidance and UR5 obstacle avoidance demonstrate the feasibility and effectiveness of the proposed framework
</details>
<h4 id="5-probabilistic-movement-primitives-based-on-weight-combinationhttpsieeexploreieeeorgdocument9959162">5. <a href="https://ieeexplore.ieee.org/document/9959162" target="_blank" rel="noopener">Probabilistic Movement Primitives Based on Weight Combination</a></h4>
<p>Jian Fu; Yucai Wang; Fan Luo; Xiaolong Li</p>
<p>2022 International Conference on Advanced Robotics and Mechatronics (ICARM)</p>
<details>
	<summary>Abstract</summary>
Demonstration learning based on Probabilistic Movement Primitives (ProMP) has been widely used in robotics skill learning. For trajectory planning in traditional ProMP, the sequential online learning method is adopted. In other words, only one data point is considered at each time, and the model parameters are updated correspondingly. This usually leads to the problem that as the number of new data points to be fitted increases, old points that could be fitted accurately by the model are now not fitted accurately. In this paper, we demonstrate that the degree of uncertainty in the prediction distribution gradually decreases as the number of observed data points increases, which is responsible for the occurrence of the above phenomenon. To solve this problem, we propose a weight combination algorithm. Every point to be fitted is processed one by one and the basis functions that fall within the highly correlated range with the point to be fitted are involved in the regression operation. Finally, the weight vector components corresponding to these basis functions are concatenated and combined to obtain the complete weight vector. We mathematically prove that the new algorithm is better than the traditional online algorithm. At the end of this paper, the simulation experiments are given to prove the rationality of the new algorithm and the accuracy higher than the traditional ProMP.
</details>
<h4 id="6-study-of-dnn-network-architecture-search-for-robot-visionhttpsieeexploreieeeorgdocument10218405">6. <a href="https://ieeexplore.ieee.org/document/10218405" target="_blank" rel="noopener">Study of DNN Network Architecture Search for Robot Vision</a></h4>
<p>Jian Fu; Qifeng Wang</p>
<p>2023 International Conference on Advanced Robotics and Mechatronics (ICARM)</p>
<details>
    <summary>Abstract</summary>
Robot vision, which integrates measurement and perception, plays an important role in robot manipulation applications. Although the current deep learning-based visual neural network models have high perception capabilities, their network structures are usually too large to be implemented on embedded devices for robot vision. In this paper, we propose neural network architecture search (NAS) that combines pre-training and pruning operations to simplify deep neural network architectures. It not only solves this problem without losing network accuracy, but also significantly alleviates the difficulties of long network computation time and redundant search space in traditional NAS methods. Finally, the experimental results show that the neural network generated by the proposed algorithm outperforms the artificially designed neural network, which demonstrates the effectiveness of the method. At the end of the paper, the rationality of the method is proved by experiments and comparisons. The performance of the new algorithm and the generated neural network is better than that of the artificially designed neural network.
</details>
<h4 id="7-task-oriented-sequential-pose-motion-primitiveshttpsieeexploreieeeorgdocument10364224">7. <a href="https://ieeexplore.ieee.org/document/10364224" target="_blank" rel="noopener">Task-oriented Sequential Pose Motion Primitives</a></h4>
<p>Jian Fu; Nan Wang</p>
<p>2023 International Annual Conference on Complex Systems and Intelligent Science October 20~22, 2023, Shenzhen, China</p>
<details>
    <summary>Abstract</summary>
Deconstructing a task into multiple phases and connecting each phase in a sequence to achieve complex motion planning is the prevailing approach in the field of robotics research. However, this paradigm also faces the problem of how to increase the generalization capacity of each stage and ensure effective smooth transitions between adjacent stages. To address this problem, we propose task-oriented sequential postural motion primitives. A number of phases are partitioned based on task characteristics, and the pose movement primitives for each phase are parameterized in a data -driven manner to facilitate the acquisition of specific skills from multiple demonstration trajectories. Besides, the problem of transitioning between temporally sequential motion primitives is modeled as a tracking problem of a moving target in order to achieve a seamless merging of movements. Finally, experiments on the Sawyer robot demonstrate the effectiveness and feasibility of the proposed method.
</details>
<h4 id="8-mixstyle-based-dual-channel-feature-fusion-for-person-re-identificationwangzhi">8. <a href="wangzhi">MixStyle-Based Dual-Channel Feature Fusion for Person Re-Identification</a></h4>
<p>Jian Fu, Xiaolong Li,  Zhu Yang</p>
<p>School of Automation, Wuhan University of Technology, Wuhan 430070, China</p>
<details>
    <summary>Abstract</summary>
The problem of Person Re-Identification is still a big challenge, as the complex network structure and unsatisfactory generalization performance of widely used deep neural networks make them unsuitable for application to real-world problems.In this paper, we propose
a global feature-based person re-identification network with strong generalization. The extracted features part contains two channels of feature fusion: the feature extraction module and the feature generalization module.The feature generalization module is a new MixStyle module added to the feature extraction module, which can effectively mix the style information of images under different domains or even the same domain to form multiple potential domain features, thus improving the generalization performance of the model.In addition, this paper also makes some improvements to the loss function by adding a new constraint on the positive sample pair distance, which makes it possible to maximizes the reduction of intra-class distance in addition to pushing the distance between different classes during the training process.Experimental results on two datasets, Market1501 and DukeMTMC, show that the method proposed in this paper has strong generalization performance on the person re-identification problem and outperforms current global featurbased person re-identification methods.
</details>
<h4 id="9-mixed-orientation-promps-and-their-application-in-attitude-trajectory-planningwangzhi">9. <a href="wangzhi">Mixed Orientation ProMPs and Their Application in Attitude Trajectory Planning</a></h4>
<p>Jian Fu, Xiaolong Li,  Zhu Yang</p>
<p>School of Automation, Wuhan University of Technology, Wuhan 430070, China</p>
<details>
    <summary>Abstract</summary>
The application of motion primitives to encode robot motion has garnered considerable attention in the field of academic research. Existing models predominantly focus on reproducing task trajectory in relation to position, often neglecting the significance of orientation. Orientation Probabilistic Movement Primitives (ProMPs) indirectly encode motion primitives for attitude by utilizing
their trajectory probabilities on Riemannian manifolds, specifically the 3-sphere S3. However, assuming a Gaussian distribution imposes constraints on its abilities. We propose Mixed Orientation ProMPs to enhance trajectory planning and minimize the occurrence of singular configurations. This model consists of multiple separate Gaussian distributions in the tangent space, enabling the approximation of any distribution. Furthermore, optimization objective functions of the Lagrangian type can incorporate constraints, such as singularity avoidance, and others. Finally, the effectiveness and reliability of the algorithm were validated through trajectory planning experiments conducted on the UR5 robotic arm.
</details>
<h4 id="10-adaptive-multi-task-human-robot-interaction-based-on-human-behavioral-intentionhttpsieeexploreieeeorgdocument9548924">10. <a href="https://ieeexplore.ieee.org/document/9548924" target="_blank" rel="noopener">Adaptive Multi-Task Human-Robot Interaction based on Human Behavioral Intention</a></h4>
<p>Jian Fu; Jinyu Du;Xiang Teng; Yuxiang Fu;Lu Wu</p>
<p>IEEE Access</p>
<details>
    <summary>Abstract</summary>
Learning from demonstrations with Probabilistic Movement Primitives (ProMPs) has been widely used in robot skill learning, especially in human-robot collaboration. Although ProMP has been extended to multi-task situations inspired by the Gaussian mixture model, it still treats each task independently. ProMP ignores the common scenario that robots conduct adaptive switching of the collaborative tasks in order to align with the instantaneous change of human intention. To solve this problem, we proposed an alternate learning-based parameter estimation method and an empirical minimum variation-based decomposition strategy with projection points, combining with linear interpolation strategy for weights, based on a Gaussian mixture model framework. Alternate learning of weights and parameters in multi-task ProMP (MTProMP) allows the robot to obtain a smooth composite trajectory planning which crosses expected via points. Decomposition strategy reflects how the desired via point state is projected onto the individual ProMP component, rendering the minimum total sum of deviations between each projection point with the respective prior. Linear interpolation is used to adjust the weights among sequential via points automatically. The proposed method and strategy are successfully extended to multi-task interaction ProMPs (MTiProMP). With MTProMP and MTiProMP, the robot can be applied to multiple tasks in industrial factories and collaborate with the worker to switch from one task to another according to changing intentions of the human. Classical via points trajectory planning experiments and human-robot collaboration experiments are performed on the Sawyer robot. The results of experiments show that MTProMP and MTiProMP with the proposed method and strategy perform better.
</details>
<h4 id="11-robot-motor-skill-transfer-with-alternate-learning-in-two-spaceshttpsdoiorg101109tnnls20203021530">11. <a href="https://doi.org/10.1109/TNNLS.2020.3021530" target="_blank" rel="noopener">Robot Motor Skill Transfer With Alternate Learning in Two Spaces</a></h4>
<p>Jian Fu; Xiang Teng; Ce Cao; Zhaojie Ju; Ping Lou</p>
<p>IEEE Transactions on Neural Networks and Learning Systems Early online 24 Sep 2020</p>
<details>
    <summary>Abstract</summary>
Recent research achievements in Learning from Demonstration (LfD) demonstrate that the reinforcement learning is effective for the robots to improve its movement skills. The current challenge mainly remains in how to generate new robot motions, which have similar preassigned performance indicator but are different from the demonstrated tasks. To deal with the above issue, this paper proposes a framework to represent the policy and conduct imitation learning and optimization for robot intelligent trajectory planning, based on the improved local weighted regression (iLWR) and policy improvement with path integral by dual perturbation (PI2-DP). Besides, the reward guided weight searching and basis function’s adaptive evolving are performed alternately in two spaces, i.e. the basis function space and the weight space, to deal with the above problem. The alternate learning process constructs a sequence of two-tuples which joins the demonstration task and new one together for motor skill transfer. So that the robot skills can be gradually learnt from similar tasks, and those skills can also correspond the demonstrated tasks to dissimilar tasks in different criterion. Classical via-points trajectory planning experiments are performed with the SCARA manipulator, a 10 DOF planar and the UR robot. These results show that the proposed method is not only feasible but also effective.
</details>
<h4 id="12-compound-heuristic-information-guided-policy-improvement-for-robot-motor-skill-acquisitionhttpswwwmdpicom2076-341710155346">12. <a href="https://www.mdpi.com/2076-3417/10/15/5346" target="_blank" rel="noopener">Compound Heuristic Information Guided Policy Improvement for Robot Motor Skill Acquisition</a></h4>
<p>Jian Fu; Cong Li; Xiang Teng；Fan Luo；Boqun Li</p>
<p>APPLIED SCIENCS. Appl. Sci. 2020, 10(15), 5346; Received: 30 June 2020 / Revised: 28 July 2020 / Accepted: 30 July 2020 / Published: 3 August 2020</p>
<details>
    <summary>Abstract</summary>
Scale-invariant feature transform (SIFT) is a popular pattern recognition method in 2D-image because it can abstracts the features which are invariant to rotation, scale zooming, brightness changing. So it demonstrates a certain stability to objects subjected to view point changing and noise distribution. However, the dimension of the SIFT descriptors is too high, and its runtime is too long. Aiming at this disadvantage, this paper propose a new method to generate feature descriptor based on hierarchical region and treat different regions differently. Improved SIFT Algorithm reclassificates dDiscovering the implicit pattern and using it as heuristic information to guide the policy search is one of the core factors to speed up the procedure of robot motor skill acquisition. This paper proposes a compound heuristic information guided reinforcement learning algorithm PI2-CMA-KCCA for policy improvement. Its structure and workflow are similar to a double closed-loop control system. The outer loop realized by Kernel Canonical Correlation Analysis (KCCA) infers the implicit nonlinear heuristic information between the joints of the robot. In addition, the inner loop operated by Covariance Matrix Adaptation (CMA) discovers the hidden linear correlations between the basis functions within the joint of the robot. These patterns which are good for learning the new task can automatically determine the mean and variance of the exploring perturbation for Path Integral Policy Improvement (PI2). Compared with classical PI2, PI2-CMA, and PI2-KCCA, PI2-CMA-KCCA can not only endow the robot with the ability to realize transfer learning of trajectory planning from the demonstration to the new task, but also complete it more efficiently. The classical via-point experiments based on SCARA and Swayer robots have validated that the proposed method has fast learning convergence and can find a solution for the new task. escriptor generating regions, using a circular area divide into 2×2+1 sub-regions instead of rectangular area in original algorithm. In the feature matching stage, setting different thresholds to 2×2 fan-shaped regions and 1 annular region, to achieve retaining right matched points as much as possible while removing wrongs. Comparing with the SIFT algorithm in some aspects, experiment results show that in the condition of fuzzy, light, rotation and affine transformation, improved SIFT algorithm can accomplish image matching test well and matching speed significantly improved.
</details>
<h4 id="13-融合kcca推断强化学习的机器人智能轨迹规划华中科技大学学报httpwwwcnkicomcnarticlecjfdtotal-hzlg201911017htm">13. <a href="http://www.cnki.com.cn/Article/CJFDTotal-HZLG201911017.htm" target="_blank" rel="noopener">融合KCCA推断强化学习的机器人智能轨迹规划（华中科技大学学报）</a></h4>
<p>傅剑; 滕翔; 曹策; 娄平。</p>
<p>《华中科技大学学报：自然科学版》，2019年第11期96-102，共7页</p>
<details>
    <summary>Abstract</summary>
针对当前模仿强化学习(LfDRL)框架面向新任务时并未考虑机器人各关节之间的联系，从而影响学习效果的不足，利用伪协方差矩阵的思想，基于再生核空间(RKHS)和广义瑞丽熵构建面向泛函指标的关节间摄动相关局部坐标系，进而设计出一种集成核典型相关分析(KCCA)与路径积分策略提升(PI2)的强化学习方法．利用学习经验数据基于KCCA推断出机器人各关节间面向轨迹规划任务的隐含非线性启发式信息，引导PI2搜索到最优/次优策略，使得机器人实现从示范轨迹规划任务到新轨迹规划任务的快速迁移学习，并高质量完成．选择顺应性装配机械手臂(SCARA)和优傲5(UR5)机器人的过单点、过两点迁移学习智能轨迹规划实验，结果表明：融合KCCA推断启发式信息的强化学习的平均代价下降率明显优于经典的PI2算法，其机器人智能轨迹规划在提升学习收敛速度的同时也提高了机器人完成新任务的精度。
</details>
<h4 id="14-watershed-algorithm-for-medical-image-segmentation-based-on-morphology-and-total-variation-modelhttpswwwworldscientificcomdoi101142s0218001419540193">14. <a href="https://www.worldscientific.com/doi/10.1142/S0218001419540193" target="_blank" rel="noopener">Watershed Algorithm for Medical Image Segmentation Based on Morphology and Total Variation Model</a></h4>
<p>Yingbo Liang; Jian Fu.</p>
<p>International Journal of Pattern Recognition and Artificial Intelligence</p>
<details>
    <summary>Abstract</summary>
The traditional watershed algorithm has the limitation of false mark in medical image segmentation, which causes over-segmentation and images to be contaminated by noise possibly during acquisition. In this study, we proposed an improved watershed segmentation algorithm based on morphological processing and total variation model (TV) for medical image segmentation. First of all, morphological gradient preprocessing is performed on MRI images of brain lesions. Secondly, the gradient images are denoised by the all-variational model. While retaining the edge information of MRI images of brain lesions, the image noise is reduced. And then, the internal and external markers are obtained by forced minimum technique, and the gradient amplitude images are corrected by using these markers. Finally, the modified gradient image is subjected to watershed transformation. The experiment of segmentation and simulation of brain lesion MRI image is carried out on MATLAB. And the segmentation results are compared with other watershed algrothims. The experimental results demonstrate that our method obtains the least number of regions, which can extract MRI images of brain lesions effectively. In addition, this method can inhibit over-segmentation, improving the segmentation results of lesions in MRI images of brain lesions.
</details>
<h4 id="15-fast-robot-motor-skill-acquisition-based-on-bayesian-inspired-policy-improvementhttpslinkspringercomchapter101007978-3-030-27529-7_31">15. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_31" target="_blank" rel="noopener">Fast Robot Motor Skill Acquisition Based on Bayesian Inspired Policy Improvement</a></h4>
<p>Jian Fu; Siyuan Shen; Ce Cao; Cong Li.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 356-367</p>
<details>
    <summary>Abstract</summary>
Learning from demonstration with the reinforcement learning (LfDRL) framework has been successfully applied to acquire the skill of robot movement. However, the optimization process of LfDRL usually converges slowly on the condition that new task is considerable different from imitation task. We in this paper proposes a ProMPs-Bayesian-PI  2  algorithms to expedite the transfer process. The main ideas is adding new heuristic information to guide optimization search other than random search from the stats of imitation learning. Specifically, we use the result of Bayesian estimation as the heuristic information to guide the PI  2  when it random search. Finally, we verify this method by UR5 and compare it with the traditional method of ProMPs-PI  2 . The experimental results show that this method is feasible and effective.
</details>
<h4 id="16-robot-motor-skill-acquisition-with-learning-in-two-spaceshttpslinkspringercomchapter101007978-3-030-27529-7_33">16. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_33" target="_blank" rel="noopener">Robot motor skill acquisition with learning in two spaces</a></h4>
<p>Jian Fu; Ce Cao; Jinyu Du; Siyuan Shen.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 379-389</p>
<details>
    <summary>Abstract</summary>
Motor skill acquisition and refinement is critical for the robot to step in human daily lives, which can endow it with the ability of autonomously performing unfamiliar tasks. However, how does the robot autonomously fulfill the new motion task with preassigned performance based on the demonstration task is still a challenge. We in this paper proposed a novel motor skill acquisition policy to conquer above problem, which is based on improved local weighted regression (iLWR), policy improvement with path integral (PI  2 ). Besides, the mixture Gaussian regression (GMR) guided self-reconstruction of basis function and the search of weight coefficient in the policy expression are performed alternately in basis function space and weight space to seek the optimal/suboptimal solution. In this way, robot can achieve the gradual acquisition of movement skills from similar tasks which is related to the demonstration to unsimilar task with different criterion. At last, the classical via-points trajectory planning experiment are performed with SCARA manipulator, NAO humanoid robot to verify that the proposed method is effective and feasible.
</details>
<h4 id="17-concurrent-probabilistic-motion-primitives-for-obstacle-avoidance-and-human-robot-collaborationhttpslinkspringercomchapter101007978-3-030-27529-7_59">17. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_59" target="_blank" rel="noopener">Concurrent probabilistic motion primitives for obstacle avoidance and human-robot collaboration</a></h4>
<p>Jian Fu; ChaoQi Wang; JingYu Du; Fan Luo.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 701-714</p>
<details>
    <summary>Abstract</summary>
The paper proposed a new method to endow a robot with the ability of human-robot collaboration and online obstacle avoidance simultaneously. In other words, we construct a probabilistic model for human-robot collaboration primitives to learn the nonlinear correlation between human and robot joint space and Cartesian space both based on interaction trajectories from the demonstration. This multidimensional probabilistic model not only helps to infer robot collaboration motion depending on the human action by the correlation between human and robot in joint space but also convenient to conduct robot obstacle avoidance reverse kinetics from cartesian space via the correlation between them. Specifically, as for the latter, a modulation matrix is established from the obstacle form to automatically generate robot obstacle avoidance trajectory in Cartesian space. Obstacle avoidance in the human-robot collaboration experimental is investigated, and its simulation results verify the feasibility and efficiency of the algorithm.
</details>
<h4 id="18-robot-intelligent-trajectory-planning-based-on-pcm-guided-reinforcement-learninghttpslinkspringercomchapter101007978-3-030-27529-7_30">18. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_30" target="_blank" rel="noopener">Robot Intelligent Trajectory Planning Based on PCM Guided Reinforcement Learning</a></h4>
<p>Xiang Teng; Jian Fu; Cong Li; ZhaoJie Ju.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 342-355</p>
<details>
    <summary>Abstract</summary>
Reinforcement Learning (RL) was successfully applied in multi-degree-of-freedoms robot to acquire motor skills, however, it hardly ever consider each joints’ relationship, or just think about the linear relationship between them. In order to find the nonlinear relationship between each degrees of freedom (DOFs), we propose a Pseudo Covariance Matrix (PCM) to guide reinforcement learning for motor skill acquisition. Specifically it combined Path Integral Policy Improvement (  PI2 ) with Kernel Canonical Correlation Analysis (KCCA), where KCCA is used to obtain the PCM in high dimensional space and record it as the heuristic information to search an optimal/sub-optimal strategy. The experiments based on robots (SCARA and UR5) demonstrate the new method is feasible and effective.
</details>
<h4 id="19-robot-motor-skill-transfer-with-alternate-learning-in-two-spaceshttpslinkspringercomchapter101007978-3-030-27529-7_33">19. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_33" target="_blank" rel="noopener">Robot Motor Skill Transfer with Alternate Learning in Two Spaces</a></h4>
<p>Jian Fu ; Sujuan Wei ; Haibo He ; Shengyong Wang</p>
<p>Conference paper. First Online: 06 August 2019. Part of the Lecture Notes in Computer Science book series (LNCS, volume 11745)</p>
<details>
    <summary>Abstract</summary>
Motor skill acquisition and refinement is critical for the robot to step in human daily lives, which can endow it with the ability of autonomously performing unfamiliar tasks. However, how does the robot autonomously fulfill the new motion task with preassigned performance based on the demonstration task is still a challenge. We in this paper proposed a novel motor skill acquisition policy to conquer above problem, which is based on improved local weighted regression (iLWR), policy improvement with path integral (PI  2 ). Besides, the mixture Gaussian regression (GMR) guided self-reconstruction of basis function and the search of weight coefficient in the policy expression are performed alternately in basis function space and weight space to seek the optimal/suboptimal solution. In this way, robot can achieve the gradual acquisition of movement skills from similar tasks which is related to the demonstration to unsimilar task with different criterion. At last, the classical via-points trajectory planning experiment are performed with SCARA manipulator, NAO humanoid robot to verify that the proposed method is effective and feasible.
</details>
<h4 id="20-基于双空间交替学习的机器人运动技能获取httpsknscnkinetkcmsdetaildetailaspxdbcodecjfddbnamecjfdlast2017filenamehzlg201710017vaidy8h89o6t8muwgg5i25mmd2bxjqbqgxbmaihpkh3cykllpq5hu3xhnewbl9wuy25mmd2fe2ibk">20. <a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2017&amp;filename=HZLG201710017&amp;v=AIDy8H89o6t8MuwGG5I%25mmd2BxJqBqGXbMAiHPkh3CyKLlPq5hu3XhnEwBL9wuy%25mmd2FE2ibK" target="_blank" rel="noopener">基于双空间交替学习的机器人运动技能获取</a></h4>
<p>傅剑,陈思明,庞牧野,娄平</p>
<p>《华中科技大学学报：自然科学版》，2017年第10期p90-94</p>
<details>
    <summary>Abstract</summary>
针对如何基于示范任务学习让机器人自主获得完成新任务的能力的难题,提出一种高斯混合回归结合路径积分策略提升(GMR-PI2)的表达、模仿和优化框架,同时采用基函数、策略表达权系数两个空间上交替搜索执行方案来解决上述问题.核心思想是当权系数探索到最佳逼近点附近时,根据经验最优轨迹集进行基函数的自重组,然后再重启权系数搜索,从而实现从示范任务到指标集约束任务的渐进运动技能获取.经典的轨迹规划过点实验结果表明该方法是有效和可行的. 
</details>
<h4 id="21-a-method-of-sift-simplifying-and-matching-algorithm-improvementhttpsieeexploreieeeorgdocument7823496">21. <a href="https://ieeexplore.ieee.org/document/7823496/" target="_blank" rel="noopener">A Method of SIFT Simplifying and Matching Algorithm Improvement</a></h4>
<p>Xinmin Zhou;Kaiyuan Wang;Jian Fu.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on: 19 January 2017</p>
<details>
    <summary>Abstract</summary>
Scale-invariant feature transform (SIFT) is a popular pattern recognition method in 2D-image because it can abstracts the features which are invariant to rotation, scale zooming, brightness changing. So it demonstrates a certain stability to objects subjected to view point changing and noise distribution. However, the dimension of the SIFT descriptors is too high, and its runtime is too long. Aiming at this disadvantage, this paper propose a new method to generate feature descriptor based on hierarchical region and treat different regions differently. Improved SIFT Algorithm reclassificates descriptor generating regions, using a circular area divide into 2×2+1 sub-regions instead of rectangular area in original algorithm. In the feature matching stage, setting different thresholds to 2×2 fan-shaped regions and 1 annular region, to achieve retaining right matched points as much as possible while removing wrongs. Comparing with the SIFT algorithm in some aspects, experiment results show that in the condition of fuzzy, light, rotation and affine transformation, improved SIFT algorithm can accomplish image matching test well and matching speed significantly improved.
</details>
<h4 id="22-spark--a-big-data-processing-platform-for-machine-learninghttpsieeexploreieeeorgdocument7823490">22. <a href="https://ieeexplore.ieee.org/document/7823490/" target="_blank" rel="noopener">SPARK – A Big Data Processing Platform for Machine Learning</a></h4>
<p>Jian Fu;Junwei Sun;Kaiyuan Wang.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on 10.1109/ICIICII.2016.0023: 19 January 2017</p>
<details>
    <summary>Abstract</summary>
Apache Spark is a distributed memory-based computing framework which is natural suitable for machine learning. Compared to Hadoop, Spark has a better ability of computing. In this paper, we analyze Spark's primary framework, core technologies, and run a machine learning instance on it. Finally, we will analyze the results and introduce our hardware equipment.
</details>
<h4 id="23-an-improved-lwr-based-forcing-term-learning-from-dmpshttpsieeexploreieeeorgdocument7823532">23. <a href="https://ieeexplore.ieee.org/document/7823532/" target="_blank" rel="noopener">An Improved LWR Based Forcing Term Learning from DMPs</a></h4>
<p>Jian Fu; Da Wei.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on: 19 January 2017</p>
<details>
    <summary>Abstract</summary>
Nowadays, endowing robots with the capability to learn is an important goal for the robotics research community. An important part of this research is learning skills. Dynamic movement primitives (DMPs) is a very powerful model to conduct learning from demonstration for robot. In this paper, we have made a great improvement on Local weighted Regression(LWR) which is an original regression technique in DMPs. Specifically, we change the phase from integrating into time average and give an logistic function to make sure the final forcing term to be zero. Then, we can make better use of min-jerk criterion demonstrate the effect and efficient.
</details>
<h4 id="24-various-robot-motor-skills-learning-with-pi2-gmrhttpsieeexploreieeeorgdocument7823533">24. <a href="https://ieeexplore.ieee.org/document/7823533/" target="_blank" rel="noopener">Various Robot Motor Skills Learning with PI2-GMR</a></h4>
<p>Jian Fu；Siming Chen.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on: 19 January 2017</p>
<details>
Learning from demonstration has been applied successfully in acquiring similar motor skills for robot. However, how to accomplish different tasks with no explicit demonstration is still a challenging issue. In this paper, we propose a novel robot skills learning method consisted of Dynamical Movement Primitives with mixture Gaussian Model Regression(DMPS-GMR) and Policy Improvement with Path Integrals (PI2). The DMPS-GMR make the robot have the ability of learning fundamental task from the rough demonstration, and then Policy Improvement with Path Integrals based on GMR (PI2-GMR) endow robot the optimal/suboptimal solution for dissimilar task from the imitated state gain from DMPS-GMR. Experimental results demonstrate that the proposed approach can make robot acquisition skill more accurately.
<summary>Abstract<summary>
</details>
<h4 id="25-gmr-based-forcing-term-learning-for-dmpshttpsieeexploreieeeorgdocument7382540">25. <a href="https://ieeexplore.ieee.org/document/7382540" target="_blank" rel="noopener">GMR based forcing term learning for DMPs</a></h4>
<p>Jian Fu ; Sujuan Wei ; Li Ning ; Kui Xiang</p>
<p>Published in: 2015 Chinese Automation Congress (CAC)</p>
<details>
    <summary>Abstract</summary>
Dynamic movement primitives (DMPs) is very powerful model to conduct learning from demonstration for robot. In this paper, we put forward a method for forcing term learning based on Gaussian Model Regression (GMR). Specifically, we apply the Gaussian Mixture Model (GMM) to model the jointly probability over data from demonstrations (desired values, positions and velocities from canonical system). Thus we can obtain the generalized prediction by means of the corresponding conditional distribution. The proposed the method has a more fitting precision than LWR (Local weighted Regression) which is a classical regression technique in DMPs. Simulation results on trajectory planning with min-jerk criterion demonstrate the effect and efficient.
</details>
<h4 id="26-a-novel-ds-gmr-coupled-primitive-for-robotic-motion-skill-learninghttpsieeexploreieeeorgdocument7373800">26. <a href="https://ieeexplore.ieee.org/document/7373800/" target="_blank" rel="noopener">A Novel DS-GMR Coupled Primitive for Robotic Motion Skill Learning</a></h4>
<p>Fu, Jian; Ning, Li; Wei, Sujuan; Zhang, Liyan.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2015 International Conference on: 3-4 Dec. 2015 ,111-115</p>
<details>
    <summary>Abstract</summary>
Imitation learning is a promising paradigm for enabling robots to autonomously perform new tasks, which is similar to the procedure of human's motion skill acquirement. In the paper, we present a novel DS-GMR coupled primitive (DGCP) for robotic motion skill learning based on imitation learning. DGCP comprises a dominated linear ordinary differential dynamic component and a GMR based forcing component. Furthermore, we carefully design the linkage mechanism of hyper parameters to achieve spatiotemporal coupling synchronically. In this way an intelligent trajectory planning in similar scenario (fulfilling target within different time and positon) could be generated spontaneously. Finally, simulation that robot perform a trajectory planning with min-jerk criteria in various duration demonstrates practical capability and efficiency of the presented method.
</details>
<h4 id="27-一种基于扩展有限状态机的业务流程管理的建模方法">27. <a href="">一种基于扩展有限状态机的业务流程管理的建模方法</a></h4>
<p>傅剑;马冰洁;熊沁怡;卫素娟;张俊.</p>
<p>专利: 2015-08-26</p>
<details>
    <summary>Abstract</summary>
</details>
<h4 id="28-online-learning-control-based-on-projected-gradient-temporal-difference-and-advanced-heuristic-dynamic-programminghttpsieeexploreieeeorgdocument6889756">28. <a href="https://ieeexplore.ieee.org/document/6889756/" target="_blank" rel="noopener">Online learning control based on projected gradient temporal difference and advanced heuristic dynamic programming</a></h4>
<p>Jian Fu; Sujuan Wei; Haibo He; Shengyong Wang.</p>
<p>Neural Networks (IJCNN), 2014 International Joint Conference on: 2014/7 ,vol. 6 no.11,3649-3656</p>
<details>
    <summary>Abstract</summary>
We present a novel online learning control algorithm (OLCPA) which comprises projected gradient temporal difference for action-value function (PGTDAVF) and advanced heuristic dynamic programming with one step delay (AHD-POSD). PGTDAVF can guarantee the convergence of temporal difference(TD)-based policy learning with smooth action-value function approximators, such as neural networks. Meanwhile, AHDPOSD is a specially designed framework for embedding PGTDAVF in to conduct online learning control. It not only coincides with the intention of temporal difference but also enables PGTDAVF to be effective under nonidentical policy environment, which results in more practicality. In this way, the proposed algorithms achieve the stability and practicability simultaneously. Finally, simulation of online learning control on a cart pole benchmark demonstrates practical control capability and efficiency of the presented method.
</details>
<h4 id="29-a-hybrid-evolving-and-gradient-strategy-for-approximating-policy-evaluation-on-online-critic-actor-learninghttpslinkspringercomchapter1010072f978-3-642-31346-2_62">29. <a href="https://link.springer.com/chapter/10.1007%2F978-3-642-31346-2_62" target="_blank" rel="noopener">A hybrid evolving and gradient strategy for approximating policy evaluation on online critic-actor learning</a></h4>
<p>Jian Fu; Haibo He; Huiying LI; Qing Liu.</p>
<p>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): 2012 ,vol 7367 ,p 555-564</p>
<details>
    <summary>Abstract</summary>
In this paper, we propose a novel strategy for approximating policy evaluation during online critic-actor learning procedure. We adopt the adaptive differential evolution with elites (ADEE) to optimize moving least square temporal difference with one step (MLSTD(0)) at the early stage which is good at global searching. Next we apply gradient method to perform local search efficiently and effectively. That solves the dilemma between explore and exploit in weight seeking for critic neural network. Simulation results on the online learning control of a cart pole benchmark demonstrate the efficiency of the presented method.
</details>
<h4 id="30-a-three-network-architecture-for-on-line-learning-and-optimization-based-on-adaptive-dynamic-programminghttpsschlrcnkinetdetailindexsjes_01sjesae920050cb56941cf0e3abe7e56aed0d">30. <a href="https://schlr.cnki.net/Detail/index/SJES_01/SJESAE920050CB56941CF0E3ABE7E56AED0D" target="_blank" rel="noopener">A three-network architecture for on-line learning and optimization based on adaptive dynamic programming</a></h4>
<p>Haibo He,Zhen Ni,Jian Fu</p>
<p>NEUROCOMPUTING. Volume 78, Issue 1. 2011. PP 3-13</p>
<details>
    <summary>Abstract</summary>
In this paper, we propose a novel adaptive dynamic programming (ADP) architecture with three networks, an action network, a critic network, and a reference network, to develop internal goal-representation for online learning and optimization. Unlike the traditional ADP design normally with an action network and a critic network, our approach integrates the third network, a reference network, into the actor-critic design framework to automatically and adaptively build an internal reinforcement signal to facilitate learning and optimization overtime to accomplish goals. We present the detailed design architecture and its associated learning algorithm to explain how effective learning and optimization can be achieved in this new ADP architecture. Furthermore, we test the performance of our architecture both on the cart-pole balancing task and the triple-link inverted pendulum balancing task, which are the popular benchmarks in the community to demonstrate its learning and control performance over time.
</details>
<h4 id="31-adaptive-dynamic-programming-with-balanced-weights-seeking-strategyhttpsieeexploreieeeorgdocument5967373">31. <a href="https://ieeexplore.ieee.org/document/5967373/" target="_blank" rel="noopener">Adaptive dynamic programming with balanced weights seeking strategy</a></h4>
<p>Jian Fu; Haibo He; Zhen Ni.</p>
<p>Adaptive Dynamic Programming And Reinforcement Learning (ADPRL), 2011 IEEE Symposium on: 29 July 2011</p>
<details>
    <summary>Abstract</summary>
In this paper we propose to integrate the recursive Levenberg-Marquardt method into the adaptive dynamic programming (ADP) design for improved learning and adaptive control performance. Our key motivation is to consider a balanced weight updating strategy with the consideration of both robustness and convergence during the online learning process. Specifically, a modified recursive Levenberg-Marquardt (LM) method is integrated into both the action network and critic network of the ADP design, and a detailed learning algorithm is proposed to implement this approach. We test the performance of our approach based on the triple link inverted pendulum, a popular benchmark in the community, to demonstrate online learning and control strategy. Experimental results and comparative study under different noise conditions demonstrate the effectiveness of this approach.
</details>
<h4 id="32-adaptive-learning-and-control-for-mimo-system-based-on-adaptive-dynamic-programminghttpsieeexploreieeeorgdocument5892895">32. <a href="https://ieeexplore.ieee.org/document/5892895/" target="_blank" rel="noopener">Adaptive Learning and Control for MIMO System Based on Adaptive Dynamic Programming</a></h4>
<p>Jian Fu; Haibo He; Xinmin Zhou.</p>
<p>Neural Networks, IEEE Transactions on: 16 June 2011 ,vol.22, no.7, ,pp.1133-1148</p>
<details>
    <summary>Abstract</summary>
Adaptive dynamic programming (ADP) is a promising research field for design of intelligent controllers, which can both learn on-the-fly and exhibit optimal behavior. Over the past decades, several generations of ADP design have been proposed in the literature, which have demonstrated many successful applications in various benchmarks and industrial applications. While many of the existing researches focus on multiple-inputs-single-output system with steepest descent search, in this paper we investigate a generalized multiple-input-multiple-output (GMIMO) ADP design for online learning and control, which is more applicable to a wide range of practical real-world applications. Furthermore, an improved weight-updating algorithm based on recursive Levenberg-Marquardt methods is presented and embodied in the GMIMO approach to improve its performance. Finally, we test the performance of this approach based on a practical complex system, namely, the learning and control of the tension and height of the looper system in a hot strip mill. Experimental results demonstrate that the proposed approach can achieve effective and robust performance.
</details>
<h4 id="33-an-adaptive-variable-strategy-pareto-differential-evolution-algorithm-for-multi-objective-optimizationhttpsieeexploreieeeorgdocument4630864">33. <a href="https://ieeexplore.ieee.org/document/4630864" target="_blank" rel="noopener">An Adaptive Variable Strategy Pareto Differential Evolution Algorithm for Multi-Objective Optimization</a></h4>
<p>Jian Fu ; Qing Liu ; Xinmin Zhou ; Kui Xiang ; Zhigang Zeng</p>
<p>Published in: 2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)</p>
<details>
    <summary>Abstract</summary>
In the paper, we propose an adaptive variable strategy Pareto differential evolution algorithm for multi-objective optimization (AVSPDE). It is different from the general adaptive DE methods which are regulated by variable parameters and applied in single-objective area. Based on the real-time information from the tournament selection set (TSS), there are two DE variants to switch dynamically during the run, in which one aims at fast convergence and the other focus on the diverse spread The theoretical analysis and the digital simulation show the presented method can achieved better performance.
</details>

    

    
    
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="publications1" class="home-section wg-pages   "  >
    <div class="container">
      








  
























  





  




<div class="row ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>实验室访问/合作发表</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">

    <h4 id="1-moflow-one-step-flow-matching-for-human-trajectory-forecasting-via-implicit-maximum-likelihood-estimation-distillationhttpsmoflow-imlegithubio">1. <a href="https://moflow-imle.github.io/" target="_blank" rel="noopener">MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation Distillation</a></h4>
<p>Yuxiang Fu; Qi Yan; Ke Li; LeLe Wang; Renjie Liao</p>
<p>CVPR 2025 Conference</p>
<details>
    <summary>Abstract</summary>
In this paper, we address the problem of human trajectory forecasting, which aims to predict the inherently multi-modal future movements of humans based on their past trajectories and other contextual cues.We propose a novel conditional flow matching model, termed MoFlow, to predict K-shot future trajectories for all agents in a given scene.We design a novel flow matching loss function that not only ensures at least one of the K sets of future trajectories is accurate but also encourages all K sets of future trajectories to be diverse and plausible.Furthermore, leveraging the implicit maximum likelihood estimation (IMLE), we propose a novel distillation method for flow models that only requires samples from the teacher model. Extensive experiments on the real-world datasets, including SportVU NBA game, ETH-UCY, and SDD, demonstrate that both our teacher flow model and the IMLE-distilled student model achieve state-of-the-art performance, generating diverse trajectories that are physically and socially plausible.Moreover, the one-step student model is significantly faster than the teacher flow model in sampling.
</details>


    

    
    
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="people" class="home-section wg-people   "  >
    <div class="container">
      







<div class="row justify-content-center people-widget">
  
  <div class="col-md-12 section-heading">
    <h1>团队成员</h1>
    
  </div>
  

  

  
  

  

  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">博士后</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%97%AB%E5%AE%87%E6%99%B4/"><img class="avatar avatar-circle" src="/zh/author/%E9%97%AB%E5%AE%87%E6%99%B4/avatar_hu50fc678a3a3b4a5ba840b331277c5ff0_866254_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%97%AB%E5%AE%87%E6%99%B4/">闫宇晴</a></h2>
      <h3>博士后</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">博士</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E8%B4%BA%E6%A2%A7%E7%AB%A5/"><img class="avatar avatar-circle" src="/zh/author/%E8%B4%BA%E6%A2%A7%E7%AB%A5/avatar_hu9af7ca8138c63378271e2b3ed48fc38c_71642_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E8%B4%BA%E6%A2%A7%E7%AB%A5/">贺梧童</a></h2>
      <h3>2022级博士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%94%B3%E6%80%9D%E8%BF%9C/"><img class="avatar avatar-circle" src="/zh/author/%E7%94%B3%E6%80%9D%E8%BF%9C/avatar_hu106205fa5b59744d9dcdb3acd94efcef_191605_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%94%B3%E6%80%9D%E8%BF%9C/">申思远</a></h2>
      <h3>2022级博士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2024级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%8E%E4%BF%8A%E9%AA%81/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%8E%E4%BF%8A%E9%AA%81/avatar_hu4fb38e6a1f60817b977015cb8b437dd0_118996_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%8E%E4%BF%8A%E9%AA%81/">李俊骁</a></h2>
      <h3>2024级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E8%B5%B5%E6%94%BF%E9%9C%96/"><img class="avatar avatar-circle" src="/zh/author/%E8%B5%B5%E6%94%BF%E9%9C%96/avatar_huf2b87e03996f95bdb8675641d98735c2_24820_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E8%B5%B5%E6%94%BF%E9%9C%96/">赵政霖</a></h2>
      <h3>2024级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%82%B9%E5%BF%97%E4%BC%A6/"><img class="avatar avatar-circle" src="/zh/author/%E9%82%B9%E5%BF%97%E4%BC%A6/avatar_hua6d47e927e941eb8395ff808cc50c449_203884_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%82%B9%E5%BF%97%E4%BC%A6/">邹志伦</a></h2>
      <h3>2024级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2023级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E8%83%A1%E5%A3%AB%E8%BE%BE/"><img class="avatar avatar-circle" src="/zh/author/%E8%83%A1%E5%A3%AB%E8%BE%BE/avatar_hu271072f92b86e467db2618bfb7b105b8_90621_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E8%83%A1%E5%A3%AB%E8%BE%BE/">胡士达</a></h2>
      <h3>2023级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%BE%90%E6%9D%B0/"><img class="avatar avatar-circle" src="/zh/author/%E5%BE%90%E6%9D%B0/avatar_hu5b1e8759637696de0e7f7803691f3f36_49269_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%BE%90%E6%9D%B0/">徐杰</a></h2>
      <h3>2023级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%AE%B7%E9%91%AB%E7%A3%8A/"><img class="avatar avatar-circle" src="/zh/author/%E6%AE%B7%E9%91%AB%E7%A3%8A/avatar_hu974afda5ee9f635a8fb795166de4266c_35540_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%AE%B7%E9%91%AB%E7%A3%8A/">殷鑫磊</a></h2>
      <h3>2023级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2022级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%99%88%E4%B8%96%E7%BF%B0/"><img class="avatar avatar-circle" src="/zh/author/%E9%99%88%E4%B8%96%E7%BF%B0/avatar_hu6a96be33a2fe7dbe4a18aa05e83ffd7e_17365_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%99%88%E4%B8%96%E7%BF%B0/">陈世翰</a></h2>
      <h3>2022级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%BB%84%E5%A4%A9%E8%BE%B0/"><img class="avatar avatar-circle" src="/zh/author/%E9%BB%84%E5%A4%A9%E8%BE%B0/avatar_hucd2780795939eabedc7021760df94b37_120755_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%BB%84%E5%A4%A9%E8%BE%B0/">黄天辰</a></h2>
      <h3>2022级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%A9%AC%E5%AF%92%E6%88%88/"><img class="avatar avatar-circle" src="/zh/author/%E9%A9%AC%E5%AF%92%E6%88%88/avatar_hu257c57f1c29c1c0ceb273011254553d3_132004_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%A9%AC%E5%AF%92%E6%88%88/">马寒戈</a></h2>
      <h3>2022级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%BE%90%E6%A2%A6%E8%BE%89/"><img class="avatar avatar-circle" src="/zh/author/%E5%BE%90%E6%A2%A6%E8%BE%89/avatar_hu8f6c96f68b80a1c1d2c0c078bddab9c3_1839329_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%BE%90%E6%A2%A6%E8%BE%89/">徐梦辉</a></h2>
      <h3>2022级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%8F%B6%E5%B0%8F%E8%9D%B6/"><img class="avatar avatar-circle" src="/zh/author/%E5%8F%B6%E5%B0%8F%E8%9D%B6/avatar_hufcf2beadb63bc0c248b45db2a667ebf8_38292_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%8F%B6%E5%B0%8F%E8%9D%B6/">叶小蝶</a></h2>
      <h3>2022级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2021级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%8E%E5%B0%8F%E9%BE%99/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%8E%E5%B0%8F%E9%BE%99/avatar_hu9f5e8b384208b7b72a0df82303f8bdd0_112155_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%8E%E5%B0%8F%E9%BE%99/">李小龙</a></h2>
      <h3>2021级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E7%AB%9E%E8%80%95/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E7%AB%9E%E8%80%95/avatar_hufb87a86d343a0582d3abceec82b315bb_166739_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E7%AB%9E%E8%80%95/">王竞耕</a></h2>
      <h3>2021级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E5%8D%97/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E5%8D%97/avatar_hub022c058f8eb5232ffc916fa1818131a_13797_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E5%8D%97/">王南</a></h2>
      <h3>2021级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%A8%E7%AB%B9/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%A8%E7%AB%B9/avatar_hu057185a07023c59d86a9f29e7cca9b4d_76641_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%A8%E7%AB%B9/">杨竹</a></h2>
      <h3>2021级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E8%B5%B5%E9%B9%8F%E5%AE%87/"><img class="avatar avatar-circle" src="/zh/author/%E8%B5%B5%E9%B9%8F%E5%AE%87/avatar_hu3e61500a71743aa543da08c0dd644883_206520_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E8%B5%B5%E9%B9%8F%E5%AE%87/">赵鹏宇</a></h2>
      <h3>2021级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%91%A8%E7%92%87/"><img class="avatar avatar-circle" src="/zh/author/%E5%91%A8%E7%92%87/avatar_hu20d4e86e985a2aea695a07dacf1fd3d5_317233_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%91%A8%E7%92%87/">周璇</a></h2>
      <h3>2021级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2020级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E7%A5%BA%E4%B8%B0/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E7%A5%BA%E4%B8%B0/avatar_huc751da6d6e50637f3a9235a014de7aed_224591_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E7%A5%BA%E4%B8%B0/">王祺丰</a></h2>
      <h3>2020级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E8%81%BF%E6%89%8D/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E8%81%BF%E6%89%8D/avatar_huda69b5ef60d6ce2bbb94145ece4dbba6_82216_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E8%81%BF%E6%89%8D/">王聿才</a></h2>
      <h3>2020级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%A8%E5%B3%B0/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%A8%E5%B3%B0/avatar_hu96c849178a23ae714219512ff2e48373_58042_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%A8%E5%B3%B0/">杨峰</a></h2>
      <h3>2020级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%92%9F%E4%BA%9A%E4%B8%9C/"><img class="avatar avatar-circle" src="/zh/author/%E9%92%9F%E4%BA%9A%E4%B8%9C/avatar_huff3b724d1a505412b6aa3b5c3d3f54b2_75359_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%92%9F%E4%BA%9A%E4%B8%9C/">钟亚东</a></h2>
      <h3>2020级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2019级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9B%BE%E4%BB%A4%E5%93%B2/"><img class="avatar avatar-circle" src="/zh/author/%E6%9B%BE%E4%BB%A4%E5%93%B2/avatar_hu2eb7e09eac163f0110c552f67e08393a_161491_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9B%BE%E4%BB%A4%E5%93%B2/">曾令哲</a></h2>
      <h3>2019级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E8%83%A1%E7%AB%8B%E5%BF%97/"><img class="avatar avatar-circle" src="/zh/author/%E8%83%A1%E7%AB%8B%E5%BF%97/avatar_hu7d8141435ebd2ee14c710678bc3550a7_146302_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E8%83%A1%E7%AB%8B%E5%BF%97/">胡立志</a></h2>
      <h3>2019级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%8E%E5%85%B4%E5%BC%BA/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%8E%E5%85%B4%E5%BC%BA/avatar_huba674ceb501abad81d069f64f3326488_187667_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%8E%E5%85%B4%E5%BC%BA/">李兴强</a></h2>
      <h3>2019级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%88%98%E8%8B%A5%E6%8B%99/"><img class="avatar avatar-circle" src="/zh/author/%E5%88%98%E8%8B%A5%E6%8B%99/avatar_hu1cc5a3f4eac22fd11546a6e5e46f592e_193461_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%88%98%E8%8B%A5%E6%8B%99/">刘若拙</a></h2>
      <h3>2019级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2018级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%9C%E7%91%BE%E7%91%9C/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%9C%E7%91%BE%E7%91%9C/avatar_hu92780c5d4d4562dfb8abce33af6fea4d_312991_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%9C%E7%91%BE%E7%91%9C/">杜瑾瑜</a></h2>
      <h3>2018级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E8%80%BF%E6%83%A0%E8%8E%89/"><img class="avatar avatar-circle" src="/zh/author/%E8%80%BF%E6%83%A0%E8%8E%89/avatar_hu34413e8a82a44888e30302f4c3356b84_87721_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E8%80%BF%E6%83%A0%E8%8E%89/">耿惠莉</a></h2>
      <h3>2018级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%8E%E8%81%AA/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%8E%E8%81%AA/avatar_hu133fef70a2a8da5cb802763765b73cf0_178618_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%8E%E8%81%AA/">李聪</a></h2>
      <h3>2018级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2017级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%A7%A6%E4%BA%98/"><img class="avatar avatar-circle" src="/zh/author/%E7%A7%A6%E4%BA%98/avatar_hu7e8230331aaa63d5547aa7c09dc5077f_210114_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%A7%A6%E4%BA%98/">秦亘</a></h2>
      <h3>2017级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%94%B3%E6%80%9D%E8%BF%9C/"><img class="avatar avatar-circle" src="/zh/author/%E7%94%B3%E6%80%9D%E8%BF%9C/avatar_hu572273b36b7e1ac22f6cb75e9110a63f_246202_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%94%B3%E6%80%9D%E8%BF%9C/">申思远</a></h2>
      <h3>2017级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%BB%95%E7%BF%94/"><img class="avatar avatar-circle" src="/zh/author/%E6%BB%95%E7%BF%94/avatar_hub26ae9c3aa7258315a08a7fb6dcc9d63_220794_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%BB%95%E7%BF%94/">滕翔</a></h2>
      <h3>2017级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E8%B6%85%E5%A5%87/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E8%B6%85%E5%A5%87/avatar_huaa061828d10c61fb383e7ecd1a23ecfa_105050_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E8%B6%85%E5%A5%87/">王超奇</a></h2>
      <h3>2017级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%A4%8F%E8%81%AA/"><img class="avatar avatar-circle" src="/zh/author/%E5%A4%8F%E8%81%AA/avatar_hufa2be68143abaa46545a49a724a20ebe_231391_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%A4%8F%E8%81%AA/">夏聪</a></h2>
      <h3>2017级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%BC%A0%E6%B4%8B/"><img class="avatar avatar-circle" src="/zh/author/%E5%BC%A0%E6%B4%8B/avatar_hudc6f535d1223d4c320b004811737341c_217961_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%BC%A0%E6%B4%8B/">张洋</a></h2>
      <h3>2017级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2016级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9B%B9%E7%AD%96/"><img class="avatar avatar-circle" src="/zh/author/%E6%9B%B9%E7%AD%96/avatar_hu1f04296c4be8a00ed08e28d0c16eba06_215284_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9B%B9%E7%AD%96/">曹策</a></h2>
      <h3>2016级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%88%98%E5%86%B0/"><img class="avatar avatar-circle" src="/zh/author/%E5%88%98%E5%86%B0/avatar_hu6871b73bf7496471fcb3db2c4935fd5f_268117_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%88%98%E5%86%B0/">刘冰</a></h2>
      <h3>2016级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2015级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%9C%E5%AE%87%E6%BE%84/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%9C%E5%AE%87%E6%BE%84/avatar_hu527081e908cc48d6e156a0daa62c3ef2_242962_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%9C%E5%AE%87%E6%BE%84/">杜宇澄</a></h2>
      <h3>2015级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%8E%E5%AA%9B%E5%AA%9B/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%8E%E5%AA%9B%E5%AA%9B/avatar_hu2e5b6c5aab9df7ac4170a5d48017e625_219405_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%8E%E5%AA%9B%E5%AA%9B/">李媛媛</a></h2>
      <h3>2015级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%AD%8F%E8%BE%BE/"><img class="avatar avatar-circle" src="/zh/author/%E9%AD%8F%E8%BE%BE/avatar_hufb741c0e08de6464dd520d4f59c8ae8a_164694_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%AD%8F%E8%BE%BE/">魏达</a></h2>
      <h3>2015级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2014级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%99%88%E6%80%9D%E6%98%8E/"><img class="avatar avatar-circle" src="/zh/author/%E9%99%88%E6%80%9D%E6%98%8E/avatar_hudbdf624b2c059ab4f0162bddea741cbd_200651_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%99%88%E6%80%9D%E6%98%8E/">陈思明</a></h2>
      <h3>2014级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%AE%81%E5%8A%9B/"><img class="avatar avatar-circle" src="/zh/author/%E5%AE%81%E5%8A%9B/avatar_huc458ee48a0578efbe867d68ea3c28029_246293_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%AE%81%E5%8A%9B/">宁力</a></h2>
      <h3>2014级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%AD%99%E4%BF%8A%E5%A8%81/"><img class="avatar avatar-circle" src="/zh/author/%E5%AD%99%E4%BF%8A%E5%A8%81/avatar_hu44f5b0efa43ddef2ccce8c451188d4b0_286992_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%AD%99%E4%BF%8A%E5%A8%81/">孙俊威</a></h2>
      <h3>2014级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E5%BC%80%E5%85%83/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E5%BC%80%E5%85%83/avatar_hucb026bc3f96bb13847f0996d71f50327_259451_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E5%BC%80%E5%85%83/">王开元</a></h2>
      <h3>2014级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2013级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%A9%AC%E5%86%B0%E6%B4%81/"><img class="avatar avatar-circle" src="/zh/author/%E9%A9%AC%E5%86%B0%E6%B4%81/avatar_hue92689cc60251b8a1046cdae6ccb2f40_66760_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%A9%AC%E5%86%B0%E6%B4%81/">马冰洁</a></h2>
      <h3>2013级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%8E%8B%E8%8A%B3%E9%BB%8E/"><img class="avatar avatar-circle" src="/zh/author/%E7%8E%8B%E8%8A%B3%E9%BB%8E/avatar_hu4d5ef34bdeab222863ff4fd9aed2fe89_84834_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%8E%8B%E8%8A%B3%E9%BB%8E/">王芳黎</a></h2>
      <h3>2013级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E5%8D%AB%E7%B4%A0%E5%A8%9F/"><img class="avatar avatar-circle" src="/zh/author/%E5%8D%AB%E7%B4%A0%E5%A8%9F/avatar_hu2257fd2b684863eca8571db9ceb3c2a9_89513_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E5%8D%AB%E7%B4%A0%E5%A8%9F/">卫素娟</a></h2>
      <h3>2013级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2011级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E7%9B%9B%E4%BC%A0%E4%B8%AD/"><img class="avatar avatar-circle" src="/zh/author/%E7%9B%9B%E4%BC%A0%E4%B8%AD/avatar_hu97ad474451105780182eb63873bc01f8_90861_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E7%9B%9B%E4%BC%A0%E4%B8%AD/">盛传中</a></h2>
      <h3>2011级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2009级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E9%9D%96%E5%BB%BA%E5%8D%8E/"><img class="avatar avatar-circle" src="/zh/author/%E9%9D%96%E5%BB%BA%E5%8D%8E/avatar_hubf6acc067fbabd8b0691e1819a8d6273_123335_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E9%9D%96%E5%BB%BA%E5%8D%8E/">靖建华</a></h2>
      <h3>2009级专业型硕士</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%9D%8E%E7%BB%98%E8%8B%B1/"><img class="avatar avatar-circle" src="/zh/author/%E6%9D%8E%E7%BB%98%E8%8B%B1/avatar_hu6dde3bc7cc79e8aa4beaf63ec99f52ed_94069_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%9D%8E%E7%BB%98%E8%8B%B1/">李绘英</a></h2>
      <h3>2009级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2008级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E6%A2%81%E8%8B%B1%E6%B3%A2/"><img class="avatar avatar-circle" src="/zh/author/%E6%A2%81%E8%8B%B1%E6%B3%A2/avatar_hu4950d0fc02d248063e78d1bdde75207e_99306_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E6%A2%81%E8%8B%B1%E6%B3%A2/">梁英波</a></h2>
      <h3>2008级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2007级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/%E4%BD%99%E6%84%BF/"><img class="avatar avatar-circle" src="/zh/author/%E4%BD%99%E6%84%BF/avatar_hu0acff41e98ab827f01ead0844b3231a7_144562_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/%E4%BD%99%E6%84%BF/">余愿</a></h2>
      <h3>2007级学术型硕士</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">Foreign Master</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/zh/author/abdoulaye-fall/"><img class="avatar avatar-circle" src="/zh/author/abdoulaye-fall/avatar_hub3d6ab95d399951720fd8ff659a39d19_62149_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/zh/author/abdoulaye-fall/">abdoulaye fall</a></h2>
      <h3>foreign master</h3>
      
      
    </div>
  </div>
  
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="projects" class="home-section wg-portfolio   "  >
    <div class="container">
      










<div class="row">
  <div class="col-12 col-lg-4 section-heading">

    <h1>近期项目</h1>
    

  </div>
  <div class="col-12 col-lg-8">



    

    

    <div class="isotope projects-container js-layout-masonry ">
      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project6/" >莱钢铁路道口无人自动化项目</a></h4>
      
      <div class="article-style">
        <p>莱钢铁路道口无人自动化项目 ​ 铁路无人道口项目是一套高度自动化</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project5/" >农业示范项目</a></h4>
      
      <div class="article-style">
        <p>农业示范项目 简介</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project7/" >蟠龙菜项目</a></h4>
      
      <div class="article-style">
        <p>蟠龙菜项目 ​ 整个自动化系统由上浆、制皮、下馅、卷包、分拣、送</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project4/" >饲喂器AIOT项目</a></h4>
      
      <div class="article-style">
        <p>饲喂器AIOT项目 简介</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project2/" >武汉理工大学电路板柔性生产线设计</a></h4>
      
      <div class="article-style">
        <p>武汉理工大学电路板柔性生产线设计 电路板柔性生产线是一套基于先</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project3/" >武汉理工大学工业自动化综合实验室的设计</a></h4>
      
      <div class="article-style">
        <p>武汉理工大学工业自动化综合实验室的设计 工业自动化综合实验室根</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/zh/project/project1/" >自动化实验室网络平台。</a></h4>
      
      <div class="article-style">
        <p>自动化实验室网络平台 “融合Web2.0技术，面向创新实践能力</p>
      </div>
      
    </div>
  </div>
</div>

        

      
    </div>

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="CurriculumVitae" class="home-section wg-featured   "  >
    <div class="container">
      




























  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>简历</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <p><font color=green size=5>※学术</font></p>
<p>傅剑，武汉理工大学教授，博士生导师，</p>
<p>智能机器人与普适计算(AIRPC)团队负责人。</p>
<p>1999年在华中理工大学(现华中科技大学)取得计算机应用硕士学位，</p>
<p>2006年在北京科技大学获得控制理论与控制工程博士学位。</p>
<p>2009-2010在美国SIT和URI做访问学者。</p>
<p>IEEE ADPRLTC(自适应动态规划和强化学习技术委员会)委员员,</p>
<p>亚太人工智能协会高级会员,</p>
<p>中国人工智能协会智能机器人专业委员会委员、</p>
<p>中国自动化学会认知计算与系统专业委员会委员、</p>
<p>中国自动化学会自适应动态规划和强化学习委员会委员。</p>
<p>担任EECR、ICACAR等多个会议的程序委员会主席或分论坛主席，</p>
<p>《IEEE Transactions on Neural Networks and Learning System》、</p>
<p>《IEEE Transactions on Cybernetics》、</p>
<p>《IEEETransactions on Industrial Electronics》等期刊</p>
<p>和ICRA、IROS、ICONIP、ICIRA等会议审稿人。</p>
<p><font color=green size=5>※教学情况</font></p>
<p><font color=blue>过去五年的课程：</font></p>
<p>机器人学（上）</p>
<p>电气控制与可编程序控制器</p>
<p>控制科学与控制工程专题</p>
<p><font color=blue>荣誉证书：</font></p>
<p>(2011-2015)指导本科生获得湖北省五篇优秀毕业论文</p>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/7.png" >
  
  
    <img src="/images/7.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/6.png" >
  
  
    <img src="/images/6.png" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<p><font color=blue>教学实习:</font></p>
<p>(2015)带领“智能绿色适应性系统”参加了xplore全球自动化大奖赛，并在德国汉诺威举行的全球总决赛中获得“优秀团队奖”。</p>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/8.jpg" >
  
  
    <img src="/images/8.jpg" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<p><font color=green size=5>※科学研究</font></p>
<p><font color=blue>学术研究项目</font></p>
<ol>
<li>
<p>主持国家自然科学基金面上项目“面向人机合作协同的机器人运动技能获取和执行研究”</p>
</li>
<li>
<p>湖北省自然科学基金“基于G2E的近似编程及移动机器人自主控制应用”</p>
</li>
<li>
<p>武汉理工大学自主创新基金“自适应动态规划若干问题研究”</p>
</li>
<li>
<p>国家自然科学基金会“网络集群多吸引子协调切换与多目标流关联研究”</p>
</li>
<li>
<p>美国自然科学基金会“职业：AIS——基于自适应动态规划的机器智能框架的综合优化预测”</p>
</li>
<li>
<p>企业项目：基于移动前端、web服务器和嵌入式设备组成的CPS智能物联系统</p>
</li>
<li>
<p>企业项目：武钢校准实验室B/S结构计量管理系统的研究与开发</p>
</li>
<li>
<p>企业项目：湛江港集装箱码头信息管理系统及无线系统扩展</p>
</li>
<li>
<p>企业项目：天铁公司热轧ACG系统的开发</p>
</li>
</ol>
<style>
.image-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 15px;
  margin: 20px 0;
}
.image-grid img {
  width: 100%;
  height: 200px; /* 统一高度 */
  object-fit: cover; /* 关键属性：裁剪填充 */
  border-radius: 8px;
  box-shadow: 0 3px 6px rgba(0,0,0,0.1);
}
</style>


    

  

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="vedios" class="home-section wg-featured   "  >
    <div class="container">
      




























  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>视频墙</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <div class="video-grid">
  <!-- 视频1 -->
  <div class="video-item">
    <video controls>
      <source src="/videos/1.mp4" type="video/mp4">
    </video>
  </div>
  <!-- 视频2 -->
  <div class="video-item">
    <video controls>
      <source src="/videos/2.mp4" type="video/mp4">
    </video>
  </div>
</div>
<style>
.video-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
  gap: 20px;
  margin: 2rem 0;
}

.video-item {
  background: #1a1a1a; /* 深色背景提升视觉统一性 */
  border-radius: 10px;
  overflow: hidden;
  box-shadow: 0 3px 8px rgba(0,0,0,0.2);
  transition: transform 0.3s ease;
}

.video-item:hover {
  transform: translateY(-5px);
}

video {
  width: 100%;
  height: 200px; /* 固定高度 */
  object-fit: cover; /* 视频裁剪填充 */
  background: #000; /* 加载前的纯色背景 */
}

/* 自定义视频控件样式 */
video::-webkit-media-controls-panel {
  background: linear-gradient(to top, rgba(0,0,0,0.7), transparent);
}

video::-webkit-media-controls-play-button,
video::-webkit-media-controls-mute-button {
  filter: invert(1); /* 白色图标 */
}
</style>


    

  

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="photo" class="home-section wg-featured   "  >
    <div class="container">
      




























  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>照片墙</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <h3 id="time2025">TIME:2025</h3>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%8716.jpg" >
  
  
    <img src="/images/%e5%9b%be%e7%89%8716.jpg" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<h3 id="time2017">TIME:2017</h3>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%871.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%871.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%872.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%872.png" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<h3 id="time2016">TIME:2016</h3>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%873.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%873.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%874.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%874.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%875.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%875.png" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<h3 id="time2015">TIME:2015</h3>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%876.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%876.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%877.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%877.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%878.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%878.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%879.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%879.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%8710.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%8710.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%8711.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%8711.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%8712.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%8712.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%8714.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%8714.png" alt=""  >
  </a>
  
  
  
  </figure>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/%e5%9b%be%e7%89%8715.png" >
  
  
    <img src="/images/%e5%9b%be%e7%89%8715.png" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<h3 id="我们的位置">我们的位置：</h3>
<p>武汉理工大学东院求实楼东附楼401</p>
<div class="image-grid">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <figure >
  
  
    <a data-fancybox="" href="/images/16.png" >
  
  
    <img src="/images/16.png" alt=""  >
  </a>
  
  
  
  </figure>

</div>
<style>
.image-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 15px;
  margin: 20px 0;
}
.image-grid img {
  width: 100%;
  height: 200px; /* 统一高度 */
  object-fit: cover; /* 关键属性：裁剪填充 */
  border-radius: 8px;
  box-shadow: 0 3px 6px rgba(0,0,0,0.1);
}
</style>


    

  

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="contact" class="home-section wg-contact   "  >
    <div class="container">
      






<div class="row contact-widget ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>Contact</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">
    

    

    <ul class="fa-ul">

      
      <li>
        <i class="fa-li fas fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email"><a href="mailto:fujian_whut@163.com">fujian_whut@163.com</a></span>
      </li>
      

      

      
      
        
        <li>
          <i class="fa-li fas fa-map-marker fa-2x" aria-hidden="true"></i>
          <span id="person-address">122 Luoshi Road, Wuhan, Hubei 430070</span>
        </li>
      

      

      

      

      
      

    </ul>

    

  </div>
</div>

    </div>
  </section>




      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    

    
    

    

    
    

    
    

    
    
    <script>
      if (window.netlifyIdentity) {
        window.netlifyIdentity.on("init", user => {
          if (!user) {
            window.netlifyIdentity.on("login", () => {
              document.location.href = "/admin/";
            });
          }
        });
      }
    </script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/wowchemy.min.eb5fcc96d414eaa162728694895a1ae2.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/zh/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/zh/terms/">Terms</a>
    
  </p>
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    
    Published with
    <a href="https://wowchemy.com" target="_blank" rel="noopener">Wowchemy</a>  —
    the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">
    open source</a> website builder that empowers creators.
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">引用</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> 复制
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> 下载
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
