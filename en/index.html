<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  
  
  <meta name="generator" content="Wowchemy 4.8.0 for Hugo">
  

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jian Fu">

  
  
  
    
  
  <meta name="description" content="Deputy Head of Automation Department">

  
  <link rel="alternate" hreflang="zh" href="/zh/">
  
  <link rel="alternate" hreflang="en-us" href="/en/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js" integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.css">

  




  


  
  
  <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
  

  
  <link rel="alternate" href="/en/index.xml" type="application/rss+xml" title="傅剑实验室主页">
  

  <link rel="manifest" href="/en/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="/en/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="傅剑实验室主页">
  <meta property="og:url" content="/en/">
  <meta property="og:title" content="傅剑实验室主页">
  <meta property="og:description" content="Deputy Head of Automation Department"><meta property="og:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png">
  <meta property="twitter:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2020-09-15T21:25:49&#43;08:00">
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite","url": "/"
}
</script>


  


  


  





  <title>傅剑实验室主页</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  
  
  
  
    <script>const isSiteThemeDark = false;</script>
  
  
  <script src="/js/load-theme.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/en/">傅剑实验室主页</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/en/">傅剑实验室主页</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/en/#posts" data-target="#posts"><span>Congratulation</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/en/#publications" data-target="#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/en/#people" data-target="#people"><span>Team Members</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/en/#projects" data-target="#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/en/#contact" data-target="#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      

      
      

      
      <li class="nav-item dropdown i18n-dropdown">
        <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-globe mr-1" aria-hidden="true"></i><span class="d-none d-lg-inline">English</span></a>
        <div class="dropdown-menu">
          <div class="dropdown-item dropdown-item-active">
            <span>English</span>
          </div>
          
          <a class="dropdown-item" href="/zh/" data-target="/zh/">
            <span>中文 (简体)</span>
          </a>
          
        </div>
      </li>
      

    </ul>

  </div>
</nav>



  











  
<span class="js-widget-page d-none"></span>





  
  
  
  




  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="about" class="home-section wg-about   "  >
    <div class="container">
      




  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle" src="/en/author/jian-fu/avatar_hu4b53893484deac3507984e4c49451eaa_24497_270x270_fill_q90_lanczos_center.jpg" alt="Jian Fu">
      

      <div class="portrait-title">
        <h2>Jian Fu</h2>
        <h3>Deputy Head of Automation Department</h3>

        
        <h3>
          
          <span>Wuhan University of Technology</span>
          
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    <h1>Biography</h1>

    <!-- Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate. -->
<!-- (1999)MSc in Master of Computer Application.Huazhong University of Science. 

(2006)Phd in Control Theory and ControlEngineering. Universityof Science and Technology Beijing.

(2009-2010)Visiting scholar in Stevens Institute of Technology and University ofRhode Island. 

Members of IEEE ADPRL TC(Adaptive Dynamic Programmingand Reinforcement Learning Technical Committee).

More than 20 papershave been published by SCI and EI in important journals andconferences at home and abroad. -->


    <div class="row">

      
      <div class="col-md-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Artificial Intelligence</li>
          
          <li>Human robot collaboration</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">Phd in Control Theory and Control Engineering, 2006</p>
              <p class="institution">University of Science and Technology Beijing</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MSc in Master of Computer Application, 1999</p>
              <p class="institution">Huazhong University of Science and Technology</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="posts" class="home-section wg-pages   "  >
    <div class="container">
      








  
























  





  




<div class="row ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>Congratulation</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">

    <!-- _**Congratulation**_

Jian Fu receives CNSF grant (general program) titled as "study on motor skill acquistion
and execution for the coordination of human-robot collaboration".

_**Congratulation**_

Sun Junwei, 2017 graduate student, received an offer from jingdong research and development in shenzhen

Wang Kaiyuan, 2017 graduate student, received an offer from HIK VISION in Nanjing

Li Yuanyuan, 2017 graduate student, received an offer from WINGTECH in Shanghai

Du Yucheng, 2017 graduate student, received an offer from electric of ShangNeng in Wuxi

Chen Siming, 2017 graduate student, received an offer from iFLYTEK in Wuhan

_**Congratulation**_

Sun Junwei, 2017 graduate student, received an offer from jingdong research and development in shenzhen

Wang Kaiyuan, 2017 graduate student, received an offer from HIK VISION in Nanjing

Li Yuanyuan, 2017 graduate student, received an offer from WINGTECH in Shanghai

Du Yucheng, 2017 graduate student, received an offer from electric of ShangNeng in Wuxi

Chen Siming, 2017 graduate student, received an offer from iFLYTEK in Wuhan -->
<p><em><strong>Congratulation</strong></em></p>
<p>Jian Fu receives CNSF grant (general program) titled as &ldquo;study on motor skill acquistion
and execution for the coordination of human-robot collaboration&rdquo;.</p>
<p>Jinyu Du&rsquo;s paper &ldquo;Adaptive Multi-Task Human-Robot Interaction Based on Human Behavioral Intention&rdquo; was accepted by IEEE access (SCI zone 2).</p>
<p><em><strong>Congratulation</strong></em></p>
<p>Liu Ruozhuo, 2022 graduate student,received an offer from Netease in Hangzhou</p>
<p>Li Xingqiang, 2022 graduate student,received an offer from Huawei in Shenzhen</p>
<p>Hu Lizhi, 2022 graduate student,received an offer from Huawei in Wuhan</p>
<p>Li Cong，2021 graduate student, received an offer from Zhongxing in Wuhan</p>
<p>Du Jingyu，2021 graduate student, received an offer from Huawei in Nanjing</p>
<p>Teng Xiang，2020 graduate student, received an offer from Huawei in Wuhan</p>
<p>Wang Chaoqi，2020 graduate student, received an offer from Huawei in Wuhan</p>
<p>Geng Huili，2020 graduate student, received an offer from CESTC</p>
<p>Zhang Yang，2019 graduate student, received an offer from Wuhan Guide Infrared Co., Ltd</p>
<p>Hang Yiweng，2019 graduate student, received an offer from WHUT School of Automation</p>
<p>Qin Gen，2019 graduate student, received an offer from Huawei in Wuhan</p>
<p>Xia Cong，2019 graduate student, received an offer from Zhongxing Telecom Equipment in Wuhan</p>
<p>Shen Siyuan，2019 graduate student, received an offer from HIK VISION in Wuhan</p>
<p>Liu Bing，2018 graduate student, received an offer from Zhongxing Telecom Equipment in Shenzhen</p>
<p>Wei Da，2018 graduate student, received an offer from Xiaohongshu in Wuhan</p>
<p>Sun Junwei, 2017 graduate student, received an offer from jingdong research and development in Shenzhen</p>
<p>Wang Kaiyuan, 2017 graduate student, received an offer from HIK VISION in Nanjing</p>
<p>Li Yuanyuan, 2017 graduate student, received an offer from WINGTECH in Shanghai</p>
<p>Du Yucheng, 2017 graduate student, received an offer from electric of ShangNeng in Wuxi</p>
<p>Chen Siming, 2017 graduate student, received an offer from iFLYTEK in Wuhan</p>


    

    
    
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="publications" class="home-section wg-pages   "  >
    <div class="container">
      








  
























  





  




<div class="row ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>publications</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">

    <h4 id="1-adversarial-domain-generalization-with-mixstylehttpsieeexploreieeeorgdocument9959388">1. <a href="https://ieeexplore.ieee.org/document/9959388" target="_blank" rel="noopener">Adversarial Domain Generalization with MixStyle</a></h4>
<p>Jian Fu and Yadong Zhong and Feng Yang</p>
<p>International Conference on Advanced Robotics and Mechatronics (ICARM)</p>
<details>
The performance of deep neural networks deteriorates when the domain representing the underlying data distribution changes during training and testing. Domain generalization expects learning from multiple source domains to improve generalization to never-before-seen target domains. We propose hybrid domain generalization using source domain and multiple latent domains as a new research scenario, and we attempt to train a generalization model that self-generates latent domain labels. In order to solve this scenario, we use the MixStyle to generate latent domain samples and assume that the styles of the samples are closely related to their domains. Therefore, we propose that GMM cluster latent domains according to style features and iteratively assign pseudo domain labels before introducing them into adversarial training. By using image style features, Our proposed method successfully synthesizes latent domains and achieves adversarial domain generalization without latent domain labels. Meanwhile, considering that the original domain labels are underutilized, this method introduces an auxiliary feature extractor to improve the performance of the model. Experiments demonstrate that our method has excellent generalization performance and outperforms classical domain generalization methods.
<summary>Abstract<summary>
</details>
<h4 id="2-online-static-obstacle-avoidance-and-offline-static-obstacle-avoidance-framework-based-on-interaction-probabilistic-movement-primitiveshttpslinkspringercomchapter101007978-981-99-2789-0_30">2. <a href="https://link.springer.com/chapter/10.1007/978-981-99-2789-0_30" target="_blank" rel="noopener">Online Static Obstacle Avoidance and Offline Static Obstacle Avoidance Framework Based on Interaction Probabilistic Movement Primitives</a></h4>
<p>Jian Fu, Feng Yang, Yadong Zhong &amp; Zhu Yang</p>
<p>School of Automation, Wuhan University of Technology, Wuhan 430070, China</p>
<details>
How to make robots self-adaptive to obstacle avoidance in the process of human-robot collaboration is one of the challenges in the community. In an actual environment, robots often encounter unanticipated obstacles that make it difficult to complete a task. So we in this paper proposed an obstacle avoidance framework based on Interaction Probabilistic Movement Primitives (iProMP), which combines online static obstacle avoidance with offline static obstacle avoidance. For unanticipated obstacles in human-robot collaboration, we find obstacle avoidance trajectories by solving the Lagrange equation, and then the product of Gaussian distribution is used to fuse the two iProMP trajectories to smoothly switch from the original trajectory to the obstacle avoidance trajectory to achieve fast online static obstacle avoidance. However, the obstacle avoidance trajectory is not optimal. When human-robot collaboration is over, the obstacle is usually not immediately cleared, and the unanticipated obstacles become the anticipated obstacles. In order to obtain a better obstacle avoidance trajectory, Path Integral Policy Improvement with Covariance Matrix Adaptation algorithm is used to train the demonstration trajectories to obtain new iProMP parameters, using the new parameters of human-robot cooperation to realize offline static obstacle avoidance. Experimental results based on two-dimensional trajectory obstacle avoidance and UR5 obstacle avoidance demonstrate the feasibility and effectiveness of the proposed framework
<summary>Abstract<summary>
</details>
<h4 id="3-probabilistic-movement-primitives-based-on-weight-combinationhttpsieeexploreieeeorgdocument9959162">3. <a href="https://ieeexplore.ieee.org/document/9959162" target="_blank" rel="noopener">Probabilistic Movement Primitives Based on Weight Combination</a></h4>
<p>Jian Fu; Yucai Wang; Fan Luo; Xiaolong Li</p>
<p>2022 International Conference on Advanced Robotics and Mechatronics (ICARM)</p>
<details>
Demonstration learning based on Probabilistic Movement Primitives (ProMP) has been widely used in robotics skill learning. For trajectory planning in traditional ProMP, the sequential online learning method is adopted. In other words, only one data point is considered at each time, and the model parameters are updated correspondingly. This usually leads to the problem that as the number of new data points to be fitted increases, old points that could be fitted accurately by the model are now not fitted accurately. In this paper, we demonstrate that the degree of uncertainty in the prediction distribution gradually decreases as the number of observed data points increases, which is responsible for the occurrence of the above phenomenon. To solve this problem, we propose a weight combination algorithm. Every point to be fitted is processed one by one and the basis functions that fall within the highly correlated range with the point to be fitted are involved in the regression operation. Finally, the weight vector components corresponding to these basis functions are concatenated and combined to obtain the complete weight vector. We mathematically prove that the new algorithm is better than the traditional online algorithm. At the end of this paper, the simulation experiments are given to prove the rationality of the new algorithm and the accuracy higher than the traditional ProMP.
<summary>Abstract<summary>
</details>
<h4 id="4-study-of-dnn-network-architecture-search-for-robot-visionhttpsieeexploreieeeorgdocument10218405">4. <a href="https://ieeexplore.ieee.org/document/10218405" target="_blank" rel="noopener">Study of DNN Network Architecture Search for Robot Vision</a></h4>
<p>Jian Fu; Qifeng Wang</p>
<p>2023 International Conference on Advanced Robotics and Mechatronics (ICARM)</p>
<details>
Robot vision, which integrates measurement and perception, plays an important role in robot manipulation applications. Although the current deep learning-based visual neural network models have high perception capabilities, their network structures are usually too large to be implemented on embedded devices for robot vision. In this paper, we propose neural network architecture search (NAS) that combines pre-training and pruning operations to simplify deep neural network architectures. It not only solves this problem without losing network accuracy, but also significantly alleviates the difficulties of long network computation time and redundant search space in traditional NAS methods. Finally, the experimental results show that the neural network generated by the proposed algorithm outperforms the artificially designed neural network, which demonstrates the effectiveness of the method. At the end of the paper, the rationality of the method is proved by experiments and comparisons. The performance of the new algorithm and the generated neural network is better than that of the artificially designed neural network.
<summary>Abstract<summary>
</details>
<h4 id="5-task-oriented-sequential-pose-motion-primitiveshttpsieeexploreieeeorgdocument10364224">5. <a href="https://ieeexplore.ieee.org/document/10364224" target="_blank" rel="noopener">Task-oriented Sequential Pose Motion Primitives</a></h4>
<p>Jian Fu; Nan Wang</p>
<p>2023 International Annual Conference on Complex Systems and Intelligent Science October 20~22, 2023, Shenzhen, China</p>
<details>
Deconstructing a task into multiple phases and connecting each phase in a sequence to achieve complex motion planning is the prevailing approach in the field of robotics research. However, this paradigm also faces the problem of how to increase the generalization capacity of each stage and ensure effective smooth transitions between adjacent stages. To address this problem, we propose task-oriented sequential postural motion primitives. A number of phases are partitioned based on task characteristics, and the pose movement primitives for each phase are parameterized in a data -driven manner to facilitate the acquisition of specific skills from multiple demonstration trajectories. Besides, the problem of transitioning between temporally sequential motion primitives is modeled as a tracking problem of a moving target in order to achieve a seamless merging of movements. Finally, experiments on the Sawyer robot demonstrate the effectiveness and feasibility of the proposed method.
<summary>Abstract<summary>
</details>
<h4 id="6-mixstyle-based-dual-channel-feature-fusion-for-person-re-identificationwangzhi">6. <a href="wangzhi">MixStyle-Based Dual-Channel Feature Fusion for Person Re-Identification</a></h4>
<p>Jian Fu, Xiaolong Li,  Zhu Yang</p>
<p>School of Automation, Wuhan University of Technology, Wuhan 430070, China</p>
<details>
The problem of Person Re-Identification is still a big challenge, as the complex network structure and unsatisfactory generalization performance of widely used deep neural networks make them unsuitable for application to real-world problems.In this paper, we propose
a global feature-based person re-identification network with strong generalization. The extracted features part contains two channels of feature fusion: the feature extraction module and the feature generalization module.The feature generalization module is a new MixStyle module added to the feature extraction module, which can effectively mix the style information of images under different domains or even the same domain to form multiple potential domain features, thus improving the generalization performance of the model.In addition, this paper also makes some improvements to the loss function by adding a new constraint on the positive sample pair distance, which makes it possible to maximizes the reduction of intra-class distance in addition to pushing the distance between different classes during the training process.Experimental results on two datasets, Market1501 and DukeMTMC, show that the method proposed in this paper has strong generalization performance on the person re-identification problem and outperforms current global featurbased person re-identification methods.
<summary>Abstract<summary>
</details>
<h4 id="7-mixed-orientation-promps-and-their-application-in-attitude-trajectory-planningwangzhi">7. <a href="wangzhi">Mixed Orientation ProMPs and Their Application in Attitude Trajectory Planning</a></h4>
<p>Jian Fu, Xiaolong Li,  Zhu Yang</p>
<p>School of Automation, Wuhan University of Technology, Wuhan 430070, China</p>
<details>
The application of motion primitives to encode robot motion has garnered considerable attention in the field of academic research. Existing models predominantly focus on reproducing task trajectory in relation to position, often neglecting the significance of orientation. Orientation Probabilistic Movement Primitives (ProMPs) indirectly encode motion primitives for attitude by utilizing
their trajectory probabilities on Riemannian manifolds, specifically the 3-sphere S3. However, assuming a Gaussian distribution imposes constraints on its abilities. We propose Mixed Orientation ProMPs to enhance trajectory planning and minimize the occurrence of singular configurations. This model consists of multiple separate Gaussian distributions in the tangent space, enabling the approximation of any distribution. Furthermore, optimization objective functions of the Lagrangian type can incorporate constraints, such as singularity avoidance, and others. Finally, the effectiveness and reliability of the algorithm were validated through trajectory planning experiments conducted on the UR5 robotic arm.
<summary>Abstract<summary>
</details>
<h4 id="8-adaptive-multi-task-human-robot-interaction-based-on-human-behavioral-intentionhttpsieeexploreieeeorgdocument9548924">8. <a href="https://ieeexplore.ieee.org/document/9548924" target="_blank" rel="noopener">Adaptive Multi-Task Human-Robot Interaction based on Human Behavioral Intention</a></h4>
<p>Jian Fu; Jinyu Du;Xiang Teng; Yuxiang Fu;Lu Wu</p>
<p>IEEE Access</p>
<details>
Learning from demonstrations with Probabilistic Movement Primitives (ProMPs) has been widely used in robot skill learning, especially in human-robot collaboration. Although ProMP has been extended to multi-task situations inspired by the Gaussian mixture model, it still treats each task independently. ProMP ignores the common scenario that robots conduct adaptive switching of the collaborative tasks in order to align with the instantaneous change of human intention. To solve this problem, we proposed an alternate learning-based parameter estimation method and an empirical minimum variation-based decomposition strategy with projection points, combining with linear interpolation strategy for weights, based on a Gaussian mixture model framework. Alternate learning of weights and parameters in multi-task ProMP (MTProMP) allows the robot to obtain a smooth composite trajectory planning which crosses expected via points. Decomposition strategy reflects how the desired via point state is projected onto the individual ProMP component, rendering the minimum total sum of deviations between each projection point with the respective prior. Linear interpolation is used to adjust the weights among sequential via points automatically. The proposed method and strategy are successfully extended to multi-task interaction ProMPs (MTiProMP). With MTProMP and MTiProMP, the robot can be applied to multiple tasks in industrial factories and collaborate with the worker to switch from one task to another according to changing intentions of the human. Classical via points trajectory planning experiments and human-robot collaboration experiments are performed on the Sawyer robot. The results of experiments show that MTProMP and MTiProMP with the proposed method and strategy perform better.
<summary>Abstract<summary>
</details>
<h4 id="9-robot-motor-skill-transfer-with-alternate-learning-in-two-spaceshttpsdoiorg101109tnnls20203021530">9. <a href="https://doi.org/10.1109/TNNLS.2020.3021530" target="_blank" rel="noopener">Robot Motor Skill Transfer With Alternate Learning in Two Spaces</a></h4>
<p>Jian Fu; Xiang Teng; Ce Cao; Zhaojie Ju; Ping Lou</p>
<p>IEEE Transactions on Neural Networks and Learning Systems Early online 24 Sep 2020</p>
<details>
Recent research achievements in Learning from Demonstration (LfD) demonstrate that the reinforcement learning is effective for the robots to improve its movement skills. The current challenge mainly remains in how to generate new robot motions, which have similar preassigned performance indicator but are different from the demonstrated tasks. To deal with the above issue, this paper proposes a framework to represent the policy and conduct imitation learning and optimization for robot intelligent trajectory planning, based on the improved local weighted regression (iLWR) and policy improvement with path integral by dual perturbation (PI2-DP). Besides, the reward guided weight searching and basis function’s adaptive evolving are performed alternately in two spaces, i.e. the basis function space and the weight space, to deal with the above problem. The alternate learning process constructs a sequence of two-tuples which joins the demonstration task and new one together for motor skill transfer. So that the robot skills can be gradually learnt from similar tasks, and those skills can also correspond the demonstrated tasks to dissimilar tasks in different criterion. Classical via-points trajectory planning experiments are performed with the SCARA manipulator, a 10 DOF planar and the UR robot. These results show that the proposed method is not only feasible but also effective.
<summary>Abstract<summary>
</details>
<h4 id="10-compound-heuristic-information-guided-policy-improvement-for-robot-motor-skill-acquisitionhttpswwwmdpicom2076-341710155346">10. <a href="https://www.mdpi.com/2076-3417/10/15/5346" target="_blank" rel="noopener">Compound Heuristic Information Guided Policy Improvement for Robot Motor Skill Acquisition</a></h4>
<p>Jian Fu; Cong Li; Xiang Teng；Fan Luo；Boqun Li</p>
<p>APPLIED SCIENCS. Appl. Sci. 2020, 10(15), 5346; Received: 30 June 2020 / Revised: 28 July 2020 / Accepted: 30 July 2020 / Published: 3 August 2020</p>
<details>
Scale-invariant feature transform (SIFT) is a popular pattern recognition method in 2D-image because it can abstracts the features which are invariant to rotation, scale zooming, brightness changing. So it demonstrates a certain stability to objects subjected to view point changing and noise distribution. However, the dimension of the SIFT descriptors is too high, and its runtime is too long. Aiming at this disadvantage, this paper propose a new method to generate feature descriptor based on hierarchical region and treat different regions differently. Improved SIFT Algorithm reclassificates dDiscovering the implicit pattern and using it as heuristic information to guide the policy search is one of the core factors to speed up the procedure of robot motor skill acquisition. This paper proposes a compound heuristic information guided reinforcement learning algorithm PI2-CMA-KCCA for policy improvement. Its structure and workflow are similar to a double closed-loop control system. The outer loop realized by Kernel Canonical Correlation Analysis (KCCA) infers the implicit nonlinear heuristic information between the joints of the robot. In addition, the inner loop operated by Covariance Matrix Adaptation (CMA) discovers the hidden linear correlations between the basis functions within the joint of the robot. These patterns which are good for learning the new task can automatically determine the mean and variance of the exploring perturbation for Path Integral Policy Improvement (PI2). Compared with classical PI2, PI2-CMA, and PI2-KCCA, PI2-CMA-KCCA can not only endow the robot with the ability to realize transfer learning of trajectory planning from the demonstration to the new task, but also complete it more efficiently. The classical via-point experiments based on SCARA and Swayer robots have validated that the proposed method has fast learning convergence and can find a solution for the new task. escriptor generating regions, using a circular area divide into 2×2+1 sub-regions instead of rectangular area in original algorithm. In the feature matching stage, setting different thresholds to 2×2 fan-shaped regions and 1 annular region, to achieve retaining right matched points as much as possible while removing wrongs. Comparing with the SIFT algorithm in some aspects, experiment results show that in the condition of fuzzy, light, rotation and affine transformation, improved SIFT algorithm can accomplish image matching test well and matching speed significantly improved.
<summary>Abstract<summary>
</details>
<h4 id="11-融合kcca推断强化学习的机器人智能轨迹规划华中科技大学学报httpwwwcnkicomcnarticlecjfdtotal-hzlg201911017htm">11. <a href="http://www.cnki.com.cn/Article/CJFDTotal-HZLG201911017.htm" target="_blank" rel="noopener">融合KCCA推断强化学习的机器人智能轨迹规划（华中科技大学学报）</a></h4>
<p>傅剑; 滕翔; 曹策; 娄平。</p>
<p>《华中科技大学学报：自然科学版》，2019年第11期96-102，共7页</p>
<details>
针对当前模仿强化学习(LfDRL)框架面向新任务时并未考虑机器人各关节之间的联系，从而影响学习效果的不足，利用伪协方差矩阵的思想，基于再生核空间(RKHS)和广义瑞丽熵构建面向泛函指标的关节间摄动相关局部坐标系，进而设计出一种集成核典型相关分析(KCCA)与路径积分策略提升(PI2)的强化学习方法．利用学习经验数据基于KCCA推断出机器人各关节间面向轨迹规划任务的隐含非线性启发式信息，引导PI2搜索到最优/次优策略，使得机器人实现从示范轨迹规划任务到新轨迹规划任务的快速迁移学习，并高质量完成．选择顺应性装配机械手臂(SCARA)和优傲5(UR5)机器人的过单点、过两点迁移学习智能轨迹规划实验，结果表明：融合KCCA推断启发式信息的强化学习的平均代价下降率明显优于经典的PI2算法，其机器人智能轨迹规划在提升学习收敛速度的同时也提高了机器人完成新任务的精度。
<summary>Abstract<summary>
</details>
<h4 id="12-watershed-algorithm-for-medical-image-segmentation-based-on-morphology-and-total-variation-modelhttpswwwworldscientificcomdoi101142s0218001419540193">12. <a href="https://www.worldscientific.com/doi/10.1142/S0218001419540193" target="_blank" rel="noopener">Watershed Algorithm for Medical Image Segmentation Based on Morphology and Total Variation Model</a></h4>
<p>Yingbo Liang; Jian Fu.</p>
<p>International Journal of Pattern Recognition and Artificial Intelligence</p>
<details>
The traditional watershed algorithm has the limitation of false mark in medical image segmentation, which causes over-segmentation and images to be contaminated by noise possibly during acquisition. In this study, we proposed an improved watershed segmentation algorithm based on morphological processing and total variation model (TV) for medical image segmentation. First of all, morphological gradient preprocessing is performed on MRI images of brain lesions. Secondly, the gradient images are denoised by the all-variational model. While retaining the edge information of MRI images of brain lesions, the image noise is reduced. And then, the internal and external markers are obtained by forced minimum technique, and the gradient amplitude images are corrected by using these markers. Finally, the modified gradient image is subjected to watershed transformation. The experiment of segmentation and simulation of brain lesion MRI image is carried out on MATLAB. And the segmentation results are compared with other watershed algrothims. The experimental results demonstrate that our method obtains the least number of regions, which can extract MRI images of brain lesions effectively. In addition, this method can inhibit over-segmentation, improving the segmentation results of lesions in MRI images of brain lesions.
<summary>Abstract<summary>
</details>
<h4 id="13-fast-robot-motor-skill-acquisition-based-on-bayesian-inspired-policy-improvementhttpslinkspringercomchapter101007978-3-030-27529-7_31">13. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_31" target="_blank" rel="noopener">Fast Robot Motor Skill Acquisition Based on Bayesian Inspired Policy Improvement</a></h4>
<p>Jian Fu; Siyuan Shen; Ce Cao; Cong Li.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 356-367</p>
<details>
Learning from demonstration with the reinforcement learning (LfDRL) framework has been successfully applied to acquire the skill of robot movement. However, the optimization process of LfDRL usually converges slowly on the condition that new task is considerable different from imitation task. We in this paper proposes a ProMPs-Bayesian-PI  2  algorithms to expedite the transfer process. The main ideas is adding new heuristic information to guide optimization search other than random search from the stats of imitation learning. Specifically, we use the result of Bayesian estimation as the heuristic information to guide the PI  2  when it random search. Finally, we verify this method by UR5 and compare it with the traditional method of ProMPs-PI  2 . The experimental results show that this method is feasible and effective.
<summary>Abstract<summary>
</details>
<h4 id="14-robot-motor-skill-acquisition-with-learning-in-two-spaceshttpslinkspringercomchapter101007978-3-030-27529-7_33">14. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_33" target="_blank" rel="noopener">Robot motor skill acquisition with learning in two spaces</a></h4>
<p>Jian Fu; Ce Cao; Jinyu Du; Siyuan Shen.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 379-389</p>
<details>
Motor skill acquisition and refinement is critical for the robot to step in human daily lives, which can endow it with the ability of autonomously performing unfamiliar tasks. However, how does the robot autonomously fulfill the new motion task with preassigned performance based on the demonstration task is still a challenge. We in this paper proposed a novel motor skill acquisition policy to conquer above problem, which is based on improved local weighted regression (iLWR), policy improvement with path integral (PI  2 ). Besides, the mixture Gaussian regression (GMR) guided self-reconstruction of basis function and the search of weight coefficient in the policy expression are performed alternately in basis function space and weight space to seek the optimal/suboptimal solution. In this way, robot can achieve the gradual acquisition of movement skills from similar tasks which is related to the demonstration to unsimilar task with different criterion. At last, the classical via-points trajectory planning experiment are performed with SCARA manipulator, NAO humanoid robot to verify that the proposed method is effective and feasible.
<summary>Abstract<summary>
</details>
<h4 id="15-concurrent-probabilistic-motion-primitives-for-obstacle-avoidance-and-human-robot-collaborationhttpslinkspringercomchapter101007978-3-030-27529-7_59">15. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_59" target="_blank" rel="noopener">Concurrent probabilistic motion primitives for obstacle avoidance and human-robot collaboration</a></h4>
<p>Jian Fu; ChaoQi Wang; JingYu Du; Fan Luo.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 701-714</p>
<details>
The paper proposed a new method to endow a robot with the ability of human-robot collaboration and online obstacle avoidance simultaneously. In other words, we construct a probabilistic model for human-robot collaboration primitives to learn the nonlinear correlation between human and robot joint space and Cartesian space both based on interaction trajectories from the demonstration. This multidimensional probabilistic model not only helps to infer robot collaboration motion depending on the human action by the correlation between human and robot in joint space but also convenient to conduct robot obstacle avoidance reverse kinetics from cartesian space via the correlation between them. Specifically, as for the latter, a modulation matrix is established from the obstacle form to automatically generate robot obstacle avoidance trajectory in Cartesian space. Obstacle avoidance in the human-robot collaboration experimental is investigated, and its simulation results verify the feasibility and efficiency of the algorithm.<summary>Abstract<summary>
</details>
<h4 id="16-robot-intelligent-trajectory-planning-based-on-pcm-guided-reinforcement-learninghttpslinkspringercomchapter101007978-3-030-27529-7_30">16. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_30" target="_blank" rel="noopener">Robot Intelligent Trajectory Planning Based on PCM Guided Reinforcement Learning</a></h4>
<p>Xiang Teng; Jian Fu; Cong Li; ZhaoJie Ju.</p>
<p>International Conference on Intelligent Robotics and Applications ICIRA 2019: Intelligent Robotics and Applications pp 342-355</p>
<details>
Reinforcement Learning (RL) was successfully applied in multi-degree-of-freedoms robot to acquire motor skills, however, it hardly ever consider each joints’ relationship, or just think about the linear relationship between them. In order to find the nonlinear relationship between each degrees of freedom (DOFs), we propose a Pseudo Covariance Matrix (PCM) to guide reinforcement learning for motor skill acquisition. Specifically it combined Path Integral Policy Improvement (  PI2 ) with Kernel Canonical Correlation Analysis (KCCA), where KCCA is used to obtain the PCM in high dimensional space and record it as the heuristic information to search an optimal/sub-optimal strategy. The experiments based on robots (SCARA and UR5) demonstrate the new method is feasible and effective.
<summary>Abstract<summary>
</details>
<h4 id="17-robot-motor-skill-transfer-with-alternate-learning-in-two-spaceshttpslinkspringercomchapter101007978-3-030-27529-7_33">17. <a href="https://link.springer.com/chapter/10.1007/978-3-030-27529-7_33" target="_blank" rel="noopener">Robot Motor Skill Transfer with Alternate Learning in Two Spaces</a></h4>
<p>Jian Fu ; Sujuan Wei ; Haibo He ; Shengyong Wang</p>
<p>Conference paper. First Online: 06 August 2019. Part of the Lecture Notes in Computer Science book series (LNCS, volume 11745)</p>
<details>
Motor skill acquisition and refinement is critical for the robot to step in human daily lives, which can endow it with the ability of autonomously performing unfamiliar tasks. However, how does the robot autonomously fulfill the new motion task with preassigned performance based on the demonstration task is still a challenge. We in this paper proposed a novel motor skill acquisition policy to conquer above problem, which is based on improved local weighted regression (iLWR), policy improvement with path integral (PI  2 ). Besides, the mixture Gaussian regression (GMR) guided self-reconstruction of basis function and the search of weight coefficient in the policy expression are performed alternately in basis function space and weight space to seek the optimal/suboptimal solution. In this way, robot can achieve the gradual acquisition of movement skills from similar tasks which is related to the demonstration to unsimilar task with different criterion. At last, the classical via-points trajectory planning experiment are performed with SCARA manipulator, NAO humanoid robot to verify that the proposed method is effective and feasible.
<summary>Abstract<summary>
</details>
<h4 id="18-基于双空间交替学习的机器人运动技能获取httpsknscnkinetkcmsdetaildetailaspxdbcodecjfddbnamecjfdlast2017filenamehzlg201710017vaidy8h89o6t8muwgg5i25mmd2bxjqbqgxbmaihpkh3cykllpq5hu3xhnewbl9wuy25mmd2fe2ibk">18. <a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2017&amp;filename=HZLG201710017&amp;v=AIDy8H89o6t8MuwGG5I%25mmd2BxJqBqGXbMAiHPkh3CyKLlPq5hu3XhnEwBL9wuy%25mmd2FE2ibK" target="_blank" rel="noopener">基于双空间交替学习的机器人运动技能获取</a></h4>
<p>傅剑,陈思明,庞牧野,娄平</p>
<p>《华中科技大学学报：自然科学版》，2017年第10期p90-94</p>
<details>
针对如何基于示范任务学习让机器人自主获得完成新任务的能力的难题,提出一种高斯混合回归结合路径积分策略提升(GMR-PI2)的表达、模仿和优化框架,同时采用基函数、策略表达权系数两个空间上交替搜索执行方案来解决上述问题.核心思想是当权系数探索到最佳逼近点附近时,根据经验最优轨迹集进行基函数的自重组,然后再重启权系数搜索,从而实现从示范任务到指标集约束任务的渐进运动技能获取.经典的轨迹规划过点实验结果表明该方法是有效和可行的. 
<summary>Abstract<summary>
</details>
<h4 id="19-a-method-of-sift-simplifying-and-matching-algorithm-improvementhttpsieeexploreieeeorgdocument7823496">19. <a href="https://ieeexplore.ieee.org/document/7823496/" target="_blank" rel="noopener">A Method of SIFT Simplifying and Matching Algorithm Improvement</a></h4>
<p>Xinmin Zhou;Kaiyuan Wang;Jian Fu.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on: 19 January 2017</p>
<details>
Scale-invariant feature transform (SIFT) is a popular pattern recognition method in 2D-image because it can abstracts the features which are invariant to rotation, scale zooming, brightness changing. So it demonstrates a certain stability to objects subjected to view point changing and noise distribution. However, the dimension of the SIFT descriptors is too high, and its runtime is too long. Aiming at this disadvantage, this paper propose a new method to generate feature descriptor based on hierarchical region and treat different regions differently. Improved SIFT Algorithm reclassificates descriptor generating regions, using a circular area divide into 2×2+1 sub-regions instead of rectangular area in original algorithm. In the feature matching stage, setting different thresholds to 2×2 fan-shaped regions and 1 annular region, to achieve retaining right matched points as much as possible while removing wrongs. Comparing with the SIFT algorithm in some aspects, experiment results show that in the condition of fuzzy, light, rotation and affine transformation, improved SIFT algorithm can accomplish image matching test well and matching speed significantly improved.
<summary>Abstract<summary>
</details>
<h4 id="20-spark--a-big-data-processing-platform-for-machine-learninghttpsieeexploreieeeorgdocument7823490">20. <a href="https://ieeexplore.ieee.org/document/7823490/" target="_blank" rel="noopener">SPARK – A Big Data Processing Platform for Machine Learning</a></h4>
<p>Jian Fu;Junwei Sun;Kaiyuan Wang.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on 10.1109/ICIICII.2016.0023: 19 January 2017</p>
<details>
Apache Spark is a distributed memory-based computing framework which is natural suitable for machine learning. Compared to Hadoop, Spark has a better ability of computing. In this paper, we analyze Spark's primary framework, core technologies, and run a machine learning instance on it. Finally, we will analyze the results and introduce our hardware equipment.
<summary>Abstract<summary>
</details>
<h4 id="21-an-improved-lwr-based-forcing-term-learning-from-dmpshttpsieeexploreieeeorgdocument7823532">21. <a href="https://ieeexplore.ieee.org/document/7823532/" target="_blank" rel="noopener">An Improved LWR Based Forcing Term Learning from DMPs</a></h4>
<p>Jian Fu; Da Wei.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on: 19 January 2017</p>
<details>
Nowadays, endowing robots with the capability to learn is an important goal for the robotics research community. An important part of this research is learning skills. Dynamic movement primitives (DMPs) is a very powerful model to conduct learning from demonstration for robot. In this paper, we have made a great improvement on Local weighted Regression(LWR) which is an original regression technique in DMPs. Specifically, we change the phase from integrating into time average and give an logistic function to make sure the final forcing term to be zero. Then, we can make better use of min-jerk criterion demonstrate the effect and efficient.
<summary>Abstract<summary>
</details>
<h4 id="22-various-robot-motor-skills-learning-with-pi2-gmrhttpsieeexploreieeeorgdocument7823533">22. <a href="https://ieeexplore.ieee.org/document/7823533/" target="_blank" rel="noopener">Various Robot Motor Skills Learning with PI2-GMR</a></h4>
<p>Jian Fu；Siming Chen.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2016 International Conference on: 19 January 2017</p>
<details>
Learning from demonstration has been applied successfully in acquiring similar motor skills for robot. However, how to accomplish different tasks with no explicit demonstration is still a challenging issue. In this paper, we propose a novel robot skills learning method consisted of Dynamical Movement Primitives with mixture Gaussian Model Regression(DMPS-GMR) and Policy Improvement with Path Integrals (PI2). The DMPS-GMR make the robot have the ability of learning fundamental task from the rough demonstration, and then Policy Improvement with Path Integrals based on GMR (PI2-GMR) endow robot the optimal/suboptimal solution for dissimilar task from the imitated state gain from DMPS-GMR. Experimental results demonstrate that the proposed approach can make robot acquisition skill more accurately.
<summary>Abstract<summary>
</details>
<h4 id="23-gmr-based-forcing-term-learning-for-dmpshttpsieeexploreieeeorgdocument7382540">23. <a href="https://ieeexplore.ieee.org/document/7382540" target="_blank" rel="noopener">GMR based forcing term learning for DMPs</a></h4>
<p>Jian Fu ; Sujuan Wei ; Li Ning ; Kui Xiang</p>
<p>Published in: 2015 Chinese Automation Congress (CAC)</p>
<details>
Dynamic movement primitives (DMPs) is very powerful model to conduct learning from demonstration for robot. In this paper, we put forward a method for forcing term learning based on Gaussian Model Regression (GMR). Specifically, we apply the Gaussian Mixture Model (GMM) to model the jointly probability over data from demonstrations (desired values, positions and velocities from canonical system). Thus we can obtain the generalized prediction by means of the corresponding conditional distribution. The proposed the method has a more fitting precision than LWR (Local weighted Regression) which is a classical regression technique in DMPs. Simulation results on trajectory planning with min-jerk criterion demonstrate the effect and efficient.
<summary>Abstract<summary>
</details>
<h4 id="24-a-novel-ds-gmr-coupled-primitive-for-robotic-motion-skill-learninghttpsieeexploreieeeorgdocument7373800">24. <a href="https://ieeexplore.ieee.org/document/7373800/" target="_blank" rel="noopener">A Novel DS-GMR Coupled Primitive for Robotic Motion Skill Learning</a></h4>
<p>Fu, Jian; Ning, Li; Wei, Sujuan; Zhang, Liyan.</p>
<p>Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), 2015 International Conference on: 3-4 Dec. 2015 ,111-115</p>
<details>
Imitation learning is a promising paradigm for enabling robots to autonomously perform new tasks, which is similar to the procedure of human's motion skill acquirement. In the paper, we present a novel DS-GMR coupled primitive (DGCP) for robotic motion skill learning based on imitation learning. DGCP comprises a dominated linear ordinary differential dynamic component and a GMR based forcing component. Furthermore, we carefully design the linkage mechanism of hyper parameters to achieve spatiotemporal coupling synchronically. In this way an intelligent trajectory planning in similar scenario (fulfilling target within different time and positon) could be generated spontaneously. Finally, simulation that robot perform a trajectory planning with min-jerk criteria in various duration demonstrates practical capability and efficiency of the presented method.
<summary>Abstract<summary>
</details>
<h4 id="25-一种基于扩展有限状态机的业务流程管理的建模方法">25. <a href="">一种基于扩展有限状态机的业务流程管理的建模方法</a></h4>
<p>傅剑;马冰洁;熊沁怡;卫素娟;张俊.</p>
<p>专利: 2015-08-26</p>
<details><summary>Abstract<summary>
</details>
<h4 id="26-online-learning-control-based-on-projected-gradient-temporal-difference-and-advanced-heuristic-dynamic-programminghttpsieeexploreieeeorgdocument6889756">26. <a href="https://ieeexplore.ieee.org/document/6889756/" target="_blank" rel="noopener">Online learning control based on projected gradient temporal difference and advanced heuristic dynamic programming</a></h4>
<p>Jian Fu; Sujuan Wei; Haibo He; Shengyong Wang.</p>
<p>Neural Networks (IJCNN), 2014 International Joint Conference on: 2014/7 ,vol. 6 no.11,3649-3656</p>
<details>
We present a novel online learning control algorithm (OLCPA) which comprises projected gradient temporal difference for action-value function (PGTDAVF) and advanced heuristic dynamic programming with one step delay (AHD-POSD). PGTDAVF can guarantee the convergence of temporal difference(TD)-based policy learning with smooth action-value function approximators, such as neural networks. Meanwhile, AHDPOSD is a specially designed framework for embedding PGTDAVF in to conduct online learning control. It not only coincides with the intention of temporal difference but also enables PGTDAVF to be effective under nonidentical policy environment, which results in more practicality. In this way, the proposed algorithms achieve the stability and practicability simultaneously. Finally, simulation of online learning control on a cart pole benchmark demonstrates practical control capability and efficiency of the presented method.
<summary>Abstract<summary>
</details>
<h4 id="27-a-hybrid-evolving-and-gradient-strategy-for-approximating-policy-evaluation-on-online-critic-actor-learninghttpslinkspringercomchapter1010072f978-3-642-31346-2_62">27. <a href="https://link.springer.com/chapter/10.1007%2F978-3-642-31346-2_62" target="_blank" rel="noopener">A hybrid evolving and gradient strategy for approximating policy evaluation on online critic-actor learning</a></h4>
<p>Jian Fu; Haibo He; Huiying LI; Qing Liu.</p>
<p>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): 2012 ,vol 7367 ,p 555-564</p>
<details>
In this paper, we propose a novel strategy for approximating policy evaluation during online critic-actor learning procedure. We adopt the adaptive differential evolution with elites (ADEE) to optimize moving least square temporal difference with one step (MLSTD(0)) at the early stage which is good at global searching. Next we apply gradient method to perform local search efficiently and effectively. That solves the dilemma between explore and exploit in weight seeking for critic neural network. Simulation results on the online learning control of a cart pole benchmark demonstrate the efficiency of the presented method.
<summary>Abstract<summary>
</details>
<h4 id="28-a-three-network-architecture-for-on-line-learning-and-optimization-based-on-adaptive-dynamic-programminghttpsschlrcnkinetdetailindexsjes_01sjesae920050cb56941cf0e3abe7e56aed0d">28. <a href="https://schlr.cnki.net/Detail/index/SJES_01/SJESAE920050CB56941CF0E3ABE7E56AED0D" target="_blank" rel="noopener">A three-network architecture for on-line learning and optimization based on adaptive dynamic programming</a></h4>
<p>Haibo He,Zhen Ni,Jian Fu</p>
<p>NEUROCOMPUTING. Volume 78, Issue 1. 2011. PP 3-13</p>
<details>
In this paper, we propose a novel adaptive dynamic programming (ADP) architecture with three networks, an action network, a critic network, and a reference network, to develop internal goal-representation for online learning and optimization. Unlike the traditional ADP design normally with an action network and a critic network, our approach integrates the third network, a reference network, into the actor-critic design framework to automatically and adaptively build an internal reinforcement signal to facilitate learning and optimization overtime to accomplish goals. We present the detailed design architecture and its associated learning algorithm to explain how effective learning and optimization can be achieved in this new ADP architecture. Furthermore, we test the performance of our architecture both on the cart-pole balancing task and the triple-link inverted pendulum balancing task, which are the popular benchmarks in the community to demonstrate its learning and control performance over time.
<summary>Abstract<summary>
</details>
<h4 id="29-adaptive-dynamic-programming-with-balanced-weights-seeking-strategyhttpsieeexploreieeeorgdocument5967373">29. <a href="https://ieeexplore.ieee.org/document/5967373/" target="_blank" rel="noopener">Adaptive dynamic programming with balanced weights seeking strategy</a></h4>
<p>Jian Fu; Haibo He; Zhen Ni.</p>
<p>Adaptive Dynamic Programming And Reinforcement Learning (ADPRL), 2011 IEEE Symposium on: 29 July 2011</p>
<details>
In this paper we propose to integrate the recursive Levenberg-Marquardt method into the adaptive dynamic programming (ADP) design for improved learning and adaptive control performance. Our key motivation is to consider a balanced weight updating strategy with the consideration of both robustness and convergence during the online learning process. Specifically, a modified recursive Levenberg-Marquardt (LM) method is integrated into both the action network and critic network of the ADP design, and a detailed learning algorithm is proposed to implement this approach. We test the performance of our approach based on the triple link inverted pendulum, a popular benchmark in the community, to demonstrate online learning and control strategy. Experimental results and comparative study under different noise conditions demonstrate the effectiveness of this approach.
<summary>Abstract<summary>
</details>
<h4 id="30-adaptive-learning-and-control-for-mimo-system-based-on-adaptive-dynamic-programminghttpsieeexploreieeeorgdocument5892895">30. <a href="https://ieeexplore.ieee.org/document/5892895/" target="_blank" rel="noopener">Adaptive Learning and Control for MIMO System Based on Adaptive Dynamic Programming</a></h4>
<p>Jian Fu; Haibo He; Xinmin Zhou.</p>
<p>Neural Networks, IEEE Transactions on: 16 June 2011 ,vol.22, no.7, ,pp.1133-1148</p>
<details>
Adaptive dynamic programming (ADP) is a promising research field for design of intelligent controllers, which can both learn on-the-fly and exhibit optimal behavior. Over the past decades, several generations of ADP design have been proposed in the literature, which have demonstrated many successful applications in various benchmarks and industrial applications. While many of the existing researches focus on multiple-inputs-single-output system with steepest descent search, in this paper we investigate a generalized multiple-input-multiple-output (GMIMO) ADP design for online learning and control, which is more applicable to a wide range of practical real-world applications. Furthermore, an improved weight-updating algorithm based on recursive Levenberg-Marquardt methods is presented and embodied in the GMIMO approach to improve its performance. Finally, we test the performance of this approach based on a practical complex system, namely, the learning and control of the tension and height of the looper system in a hot strip mill. Experimental results demonstrate that the proposed approach can achieve effective and robust performance.
<summary>Abstract<summary>
</details>
<h4 id="31-an-adaptive-variable-strategy-pareto-differential-evolution-algorithm-for-multi-objective-optimizationhttpsieeexploreieeeorgdocument4630864">31. <a href="https://ieeexplore.ieee.org/document/4630864" target="_blank" rel="noopener">An Adaptive Variable Strategy Pareto Differential Evolution Algorithm for Multi-Objective Optimization</a></h4>
<p>Jian Fu ; Qing Liu ; Xinmin Zhou ; Kui Xiang ; Zhigang Zeng</p>
<p>Published in: 2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)</p>
<details>
In the paper, we propose an adaptive variable strategy Pareto differential evolution algorithm for multi-objective optimization (AVSPDE). It is different from the general adaptive DE methods which are regulated by variable parameters and applied in single-objective area. Based on the real-time information from the tournament selection set (TSS), there are two DE variants to switch dynamically during the run, in which one aims at fast convergence and the other focus on the diverse spread The theoretical analysis and the digital simulation show the presented method can achieved better performance.
<summary>Abstract<summary>
</details>

    

    
    
    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="people" class="home-section wg-people   "  >
    <div class="container">
      







<div class="row justify-content-center people-widget">
  
  <div class="col-md-12 section-heading">
    <h1>团队成员</h1>
    
  </div>
  

  

  
  

  

  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2024级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/junxiao-zhao/"><img class="avatar avatar-circle" src="/en/author/junxiao-zhao/avatar_hu4fb38e6a1f60817b977015cb8b437dd0_118996_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/junxiao-zhao/">JunXiao Zhao</a></h2>
      <h3>2024 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zhenglin-zhao/"><img class="avatar avatar-circle" src="/en/author/zhenglin-zhao/avatar_huf2b87e03996f95bdb8675641d98735c2_24820_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zhenglin-zhao/">ZhengLin Zhao</a></h2>
      <h3>2024 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zhilun-zou/"><img class="avatar avatar-circle" src="/en/author/zhilun-zou/avatar_hua6d47e927e941eb8395ff808cc50c449_203884_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zhilun-zou/">ZhiLun Zou</a></h2>
      <h3>2024 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2022级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/hange-ma/"><img class="avatar avatar-circle" src="/en/author/hange-ma/avatar_hu257c57f1c29c1c0ceb273011254553d3_132004_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/hange-ma/">HanGe Ma</a></h2>
      <h3>2022 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/menghui-xu/"><img class="avatar avatar-circle" src="/en/author/menghui-xu/avatar_hu279a11eb142bca10279d732e755a07ee_86961_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/menghui-xu/">MengHui Xu</a></h2>
      <h3>2022 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/shihan-chen/"><img class="avatar avatar-circle" src="/en/author/shihan-chen/avatar_hu6a96be33a2fe7dbe4a18aa05e83ffd7e_17365_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/shihan-chen/">ShiHan Chen</a></h2>
      <h3>2022 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/tianchen-huang/"><img class="avatar avatar-circle" src="/en/author/tianchen-huang/avatar_hucd2780795939eabedc7021760df94b37_120755_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/tianchen-huang/">TianChen Huang</a></h2>
      <h3>2022 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/xiaodie-ye/"><img class="avatar avatar-circle" src="/en/author/xiaodie-ye/avatar_hufcf2beadb63bc0c248b45db2a667ebf8_38292_270x270_fill_q90_lanczos_center.jpg" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/xiaodie-ye/">XiaoDie Ye</a></h2>
      <h3>2022 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2021级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/gengjing-wang/"><img class="avatar avatar-circle" src="/en/author/gengjing-wang/avatar_hufb87a86d343a0582d3abceec82b315bb_166739_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/gengjing-wang/">GengJing Wang</a></h2>
      <h3>2021 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/longxiao-li/"><img class="avatar avatar-circle" src="/en/author/longxiao-li/avatar_hu9f5e8b384208b7b72a0df82303f8bdd0_112155_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/longxiao-li/">LongXiao Li</a></h2>
      <h3>2021 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/nan-wang/"><img class="avatar avatar-circle" src="/en/author/nan-wang/avatar_hub022c058f8eb5232ffc916fa1818131a_13797_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/nan-wang/">Nan Wang</a></h2>
      <h3>2021 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/xuan-zhou/"><img class="avatar avatar-circle" src="/en/author/xuan-zhou/avatar_hu20d4e86e985a2aea695a07dacf1fd3d5_317233_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/xuan-zhou/">Xuan Zhou</a></h2>
      <h3>2021 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yupeng-zhao/"><img class="avatar avatar-circle" src="/en/author/yupeng-zhao/avatar_hu3e61500a71743aa543da08c0dd644883_206520_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yupeng-zhao/">YuPeng Zhao</a></h2>
      <h3>2021 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zhu-yang/"><img class="avatar avatar-circle" src="/en/author/zhu-yang/avatar_hu057185a07023c59d86a9f29e7cca9b4d_76641_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zhu-yang/">Zhu Yang</a></h2>
      <h3>2021 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2020级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/feng-yang/"><img class="avatar avatar-circle" src="/en/author/feng-yang/avatar_hu96c849178a23ae714219512ff2e48373_58042_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/feng-yang/">Feng Yang</a></h2>
      <h3>2020 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/qifeng-wang/"><img class="avatar avatar-circle" src="/en/author/qifeng-wang/avatar_huc751da6d6e50637f3a9235a014de7aed_224591_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/qifeng-wang/">QiFeng Wang</a></h2>
      <h3>2020 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yadong-zhong/"><img class="avatar avatar-circle" src="/en/author/yadong-zhong/avatar_huff3b724d1a505412b6aa3b5c3d3f54b2_75359_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yadong-zhong/">YaDong Zhong</a></h2>
      <h3>2020 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yucai-wang/"><img class="avatar avatar-circle" src="/en/author/yucai-wang/avatar_huda69b5ef60d6ce2bbb94145ece4dbba6_82216_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yucai-wang/">YuCai Wang</a></h2>
      <h3>2020 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2019级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/qiangxing-li/"><img class="avatar avatar-circle" src="/en/author/qiangxing-li/avatar_huba674ceb501abad81d069f64f3326488_187667_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/qiangxing-li/">QiangXing Li</a></h2>
      <h3>2019 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zheling-zeng/"><img class="avatar avatar-circle" src="/en/author/zheling-zeng/avatar_hu2eb7e09eac163f0110c552f67e08393a_161491_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zheling-zeng/">ZheLing Zeng</a></h2>
      <h3>2019 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zhili-hu/"><img class="avatar avatar-circle" src="/en/author/zhili-hu/avatar_hu7d8141435ebd2ee14c710678bc3550a7_146302_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zhili-hu/">ZhiLi HU</a></h2>
      <h3>2019 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zhuoruo-liu/"><img class="avatar avatar-circle" src="/en/author/zhuoruo-liu/avatar_hu1cc5a3f4eac22fd11546a6e5e46f592e_193461_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zhuoruo-liu/">ZhuoRuo Liu</a></h2>
      <h3>2019 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2018级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/chong-li/"><img class="avatar avatar-circle" src="/en/author/chong-li/avatar_hu133fef70a2a8da5cb802763765b73cf0_178618_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/chong-li/">Chong Li</a></h2>
      <h3>2018 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/huili-geng/"><img class="avatar avatar-circle" src="/en/author/huili-geng/avatar_hu34413e8a82a44888e30302f4c3356b84_87721_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/huili-geng/">HuiLi Geng</a></h2>
      <h3>2018 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/jinyu-du/"><img class="avatar avatar-circle" src="/en/author/jinyu-du/avatar_hu92780c5d4d4562dfb8abce33af6fea4d_312991_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/jinyu-du/">JinYu Du</a></h2>
      <h3>2018 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2017级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/chaoqi-wang/"><img class="avatar avatar-circle" src="/en/author/chaoqi-wang/avatar_huaa061828d10c61fb383e7ecd1a23ecfa_105050_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/chaoqi-wang/">ChaoQi Wang</a></h2>
      <h3>2017 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/chong-xia/"><img class="avatar avatar-circle" src="/en/author/chong-xia/avatar_hufa2be68143abaa46545a49a724a20ebe_231391_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/chong-xia/">Chong Xia</a></h2>
      <h3>2017 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/gen-qin/"><img class="avatar avatar-circle" src="/en/author/gen-qin/avatar_hu7e8230331aaa63d5547aa7c09dc5077f_210114_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/gen-qin/">Gen Qin</a></h2>
      <h3>2017 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/siyuan-shen/"><img class="avatar avatar-circle" src="/en/author/siyuan-shen/avatar_hu572273b36b7e1ac22f6cb75e9110a63f_246202_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/siyuan-shen/">SiYuan Shen</a></h2>
      <h3>2017 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/xiang-teng/"><img class="avatar avatar-circle" src="/en/author/xiang-teng/avatar_hub26ae9c3aa7258315a08a7fb6dcc9d63_220794_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/xiang-teng/">Xiang Teng</a></h2>
      <h3>2017 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/zhang-yang/"><img class="avatar avatar-circle" src="/en/author/zhang-yang/avatar_hudc6f535d1223d4c320b004811737341c_217961_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/zhang-yang/">zhang yang</a></h2>
      <h3>2017 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2016级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/bing-liu/"><img class="avatar avatar-circle" src="/en/author/bing-liu/avatar_hu6871b73bf7496471fcb3db2c4935fd5f_268117_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/bing-liu/">Bing Liu</a></h2>
      <h3>2016 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/ce-cao/"><img class="avatar avatar-circle" src="/en/author/ce-cao/avatar_hu1f04296c4be8a00ed08e28d0c16eba06_215284_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/ce-cao/">Ce Cao</a></h2>
      <h3>2016 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2015级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/da-wei/"><img class="avatar avatar-circle" src="/en/author/da-wei/avatar_hufb741c0e08de6464dd520d4f59c8ae8a_164694_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/da-wei/">Da Wei</a></h2>
      <h3>2015 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yuanyuan-li/"><img class="avatar avatar-circle" src="/en/author/yuanyuan-li/avatar_hu2e5b6c5aab9df7ac4170a5d48017e625_219405_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yuanyuan-li/">YuanYuan Li</a></h2>
      <h3>2015 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yucheng-du/"><img class="avatar avatar-circle" src="/en/author/yucheng-du/avatar_hu527081e908cc48d6e156a0daa62c3ef2_242962_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yucheng-du/">YuCheng Du</a></h2>
      <h3>2015 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2014级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/junwei-sun/"><img class="avatar avatar-circle" src="/en/author/junwei-sun/avatar_hu44f5b0efa43ddef2ccce8c451188d4b0_286992_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/junwei-sun/">JunWei Sun</a></h2>
      <h3>2014 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/kaiyuan-wang/"><img class="avatar avatar-circle" src="/en/author/kaiyuan-wang/avatar_hucb026bc3f96bb13847f0996d71f50327_259451_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/kaiyuan-wang/">KaiYuan Wang</a></h2>
      <h3>2014 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/li-ning/"><img class="avatar avatar-circle" src="/en/author/li-ning/avatar_huc458ee48a0578efbe867d68ea3c28029_246293_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/li-ning/">Li Ning</a></h2>
      <h3>2014 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/siming-chen/"><img class="avatar avatar-circle" src="/en/author/siming-chen/avatar_hudbdf624b2c059ab4f0162bddea741cbd_200651_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/siming-chen/">SiMing Chen</a></h2>
      <h3>2014 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2013级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/bingjie-ma/"><img class="avatar avatar-circle" src="/en/author/bingjie-ma/avatar_hue92689cc60251b8a1046cdae6ccb2f40_66760_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/bingjie-ma/">BingJie Ma</a></h2>
      <h3>2013 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/fangli-wang/"><img class="avatar avatar-circle" src="/en/author/fangli-wang/avatar_hu4d5ef34bdeab222863ff4fd9aed2fe89_84834_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/fangli-wang/">FangLi Wang</a></h2>
      <h3>2013 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/sujuan-wei/"><img class="avatar avatar-circle" src="/en/author/sujuan-wei/avatar_hu2257fd2b684863eca8571db9ceb3c2a9_89513_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/sujuan-wei/">SuJuan Wei</a></h2>
      <h3>2013 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2011级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/chuanzhong-sheng/"><img class="avatar avatar-circle" src="/en/author/chuanzhong-sheng/avatar_hu97ad474451105780182eb63873bc01f8_90861_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/chuanzhong-sheng/">ChuanZhong Sheng</a></h2>
      <h3>2011 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2009级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/huiying-li/"><img class="avatar avatar-circle" src="/en/author/huiying-li/avatar_hu6dde3bc7cc79e8aa4beaf63ec99f52ed_94069_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/huiying-li/">huiying li</a></h2>
      <h3>2009 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/jianhua-jing/"><img class="avatar avatar-circle" src="/en/author/jianhua-jing/avatar_hubf6acc067fbabd8b0691e1819a8d6273_123335_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/jianhua-jing/">JianHua Jing</a></h2>
      <h3>2009 Professional Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2008级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yingbo-liang/"><img class="avatar avatar-circle" src="/en/author/yingbo-liang/avatar_hu4950d0fc02d248063e78d1bdde75207e_99306_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yingbo-liang/">YingBo Liang</a></h2>
      <h3>2008 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">2007级</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/yuan-yu/"><img class="avatar avatar-circle" src="/en/author/yuan-yu/avatar_hu0acff41e98ab827f01ead0844b3231a7_144562_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/yuan-yu/">Yuan Yu</a></h2>
      <h3>2007 Academic Master</h3>
      
      
    </div>
  </div>
  
  
  

  

  
  
  

  

  
  
  

  

  
  
  

  
  <div class="col-md-12">
    <h2 class="mb-4">Foreign Master</h2>
  </div>
  

  
  
  
  
  
    
  
  <div class="col-12 col-sm-auto people-person">
    
    
      
      
    
    
      
      <a href="/en/author/abdoulaye-fall/"><img class="avatar avatar-circle" src="/en/author/abdoulaye-fall/avatar_hub3d6ab95d399951720fd8ff659a39d19_62149_270x270_fill_lanczos_center_3.png" alt="Avatar"></a>
    

    <div class="portrait-title">
      <h2><a href="/en/author/abdoulaye-fall/">ABDOULAYE FALL</a></h2>
      <h3>foreign master</h3>
      
      
    </div>
  </div>
  
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="projects" class="home-section wg-portfolio   "  >
    <div class="container">
      










<div class="row">
  <div class="col-12 col-lg-4 section-heading">

    <h1>Recent Projects</h1>
    

  </div>
  <div class="col-12 col-lg-8">



    

    

    <div class="isotope projects-container js-layout-masonry ">
      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/en/project/project2/" >Design of flexible production line of circuit board of Wuhan University of Technology</a></h4>
      
      <div class="article-style">
        <p>Design of flexible production line of circuit board of Wuhan University of Technology. Flexible production line of circuit board is an intelligent flexible production line to product circuit board, which is developed based on a set of advanced manufacturing concept, the process of production includes intelligent production, processing, assembly, and warehousing, digital logistics tracking and so on.</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/en/project/project3/" >Design of WHUT industrial automation comprehensive laboratory</a></h4>
      
      <div class="article-style">
        <p>Design of WHUT industrial automation comprehensive laboratory The industrial automation comprehensive laboratory designed is customedas meeting the needs of the school of automation teaching tasks,which gives priority for automation class and covers manyprofessional core technology including information, electronics,computer, industrial robots in the field of teaching, scientificresearch and practical needs.</p>
      </div>
      
    </div>
  </div>
</div>

        

      

        
        
        

        
          








  





<div class="project-card project-item isotope-item ">
  <div class="card">
    
    <div class="card-text">
      <h4><a href="/en/project/project1/" >the Automation Laboratory Network Platform</a></h4>
      
      <div class="article-style">
        <p>the Automation Laboratory Network Platform. “The automation lab network platform fusing web 2.0 technology and facingcultivation of innovation and practice ability</p>
      </div>
      
    </div>
  </div>
</div>

        

      
    </div>

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="CurriculumVitae" class="home-section wg-featured   "  >
    <div class="container">
      




























  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Curriculum Vitae</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <p><font color=green size=5>※Curriculum</font></p>
<p>(1999)MSc in Master of Computer Application.Huazhong University of Science.</p>
<p>(2006)Phd in Control Theory and ControlEngineering. Universityof Science and Technology Beijing.</p>
<p>(2009-2010)Visiting scholar in Stevens Institute of Technology and University ofRhode Island.</p>
<p>Members of IEEE ADPRLTC(Adaptive Dynamic Programmingand Reinforcement Learning Technical Committee).</p>
<p>Member of CAA ADPRLTC(Adaptive Dynamic Programmingand Reinforcement Learning Technical Committee).</p>
<p>Member of new energy control group in Technical Committee on Control Theory, Chinese Association of Automation.</p>
<p>More than 20 papershave been published by SCI and EI in important journals andconferences at home and abroad.</p>
<p><font color=green size=5>※Teaching situation</font></p>
<p><font color=blue>The courses in the last five years：</font></p>
<p>Embedded systemsand Controls；</p>
<p>Sensingand Detection technology；</p>
<p>Adjustthe instrument and Process control system；</p>
<p>Electricaland Programmable Controller；</p>
<p>Industrialcontrol network and Fieldbus；</p>
<p>VisaulBasic；</p>
<p><font color=blue>Scholarship and Prize：</font></p>
<p>(2011-2015)Instruct undergraduates to obtain five excellent graduation theses of Hubeiprovince</p>
  <img src="https://img-blog.csdnimg.cn/20200916132559750.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center" width="100%">
  <img src="https://img-blog.csdnimg.cn/2020091613284892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center" width="100%">
<p><font color=blue>Teaching Practice:</font></p>
<p>(2015)Leading&quot; smart &amp; green fitness system &ldquo;participate in the xplore global automation grand and won the“excellent team award” in the global finals in Hanover, Germany.</p>
<p><img src="https://img-blog.csdnimg.cn/20200916133326352.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
  <!-- <font face="黑体" color=green size=5>我是黑体，绿色，尺寸为5</font> -->
<p><font color=green size=5>※Scientific research</font></p>
<p><font color=blue>Academic research projects</font></p>
<ol>
<li>
<p>Presided over the general project of NSFC(National Natural Science Foundation of China) &ldquo;Research on acquisition and execution of robot motor skills for man-machine cooperation&rdquo;</p>
</li>
<li>
<p>Natural science foundation in Hubei Province “Approximatedynamic programming based on G2E and autonomous control applicationof mobile robot”</p>
</li>
<li>
<p>Independent innovation fund in Wuhan University of Technology “Thestudy of several problems in adaptive dynamic programming”</p>
</li>
<li>
<p>Nationalnatural science foundation “Networkcluster multi-attractor coordination switching and multi-target flowassociative research”</p>
</li>
<li>
<p>Americannatural science foundation“CAREER:AIS&mdash;An Integrated Optimized and Prediction
Framework forMachine Intelligence Base on Adaptive Dynamic Programming”</p>
</li>
<li>
<p>Enterpriseproject：CPS intelligent IOT system based on mobile front end, web server and embedded device</p>
</li>
<li>
<p>Enterpriseproject：Researchand development of B/S structural metering management system of Wuhansteel calibration laboratory</p>
</li>
<li>
<p>Enterpriseproject：Theinformation management system and wireless system expansion of thecontainer terminal in Zhanjiang port</p>
</li>
<li>
<p>Enterpriseproject：Developmentof ACG system in hot rolling of Tian Tie Company</p>
</li>
</ol>


    

  

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="photo" class="home-section wg-featured   "  >
    <div class="container">
      




























  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Photo</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <h3 id="time2017">TIME:2017</h3>
<!-- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917202720383.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917202742179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center) -->
<table>
    <tr>
        <td ><img src="https://img-blog.csdnimg.cn/20200917202720383.png" width="500" height="500"></td>
        <td ><img src="https://img-blog.csdnimg.cn/20200917202742179.png" width="500" height="500"></td>
    </tr>
</table>
<h3 id="time2016">TIME:2016</h3>
<!-- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917202811739.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917202849881.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020091720292477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center) -->
<table>
    <tr>
        <td colspan="2"><img src="https://img-blog.csdnimg.cn/20200917202811739.png" ></td>
    </tr>
    <tr>
        <td><img src="https://img-blog.csdnimg.cn/20200917202849881.png"  ></td>
        <td ><img src="https://img-blog.csdnimg.cn/2020091720292477.png"  ></td>
    </tr>
</table>
<h3 id="time2015">TIME:2015</h3>
<!-- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917202943455.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917203002258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917203017996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020091720303740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020091720310156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917203124148.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020091720313933.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917203213274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917203227361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center) -->
<table>
    <tr>
        <td><img src="https://img-blog.csdnimg.cn/20200917202943455.png"  ></td>
    </tr>
    <tr>
        <td ><img src="https://img-blog.csdnimg.cn/20200917203002258.png"  ></td>
    </tr>
</table>
<table>
    <tr>
        <td ><img src="https://img-blog.csdnimg.cn/20200917203017996.png" display:block;border:none; ></td>
        <td><img src="https://img-blog.csdnimg.cn/2020091720313933.png" display:block;border:none; ></td>
    </tr>
</table>
<table>
    <tr>
        <td><img src="https://img-blog.csdnimg.cn/2020091720303740.png"  ></td>
        <td ><img src="https://img-blog.csdnimg.cn/2020091720310156.png"  ></td>
        <td ><img src="https://img-blog.csdnimg.cn/20200917203124148.png"  ></td>
    </tr>
</table>
<table>
    <tr>
        <td><img src="https://img-blog.csdnimg.cn/20200917203213274.png"  ></td>
    </tr>
    <tr>
        <td ><img src="https://img-blog.csdnimg.cn/20200917203227361.png"  ></td>
    </tr>
</table>
<h3 id="我们的位置">我们的位置：</h3>
<!-- ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917203153953.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzM0MzE5,size_16,color_FFFFFF,t_70#pic_center) -->
<table>
    <tr>
        <td><img src="https://img-blog.csdnimg.cn/20200917203153953.png"  ></td>
    </tr>
</table>

    

  

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  
  

  

  
  

  
  
  

  
  
  
  
  

  
  

  

  
  

  <section id="contact" class="home-section wg-contact   "  >
    <div class="container">
      






<div class="row contact-widget ">
  
    
      <div class="col-12 col-lg-4 section-heading">
        <h1>Contact</h1>
        
      </div>
    
  
  <div class="col-12 col-lg-8">
    

    

    <ul class="fa-ul">

      
      <li>
        <i class="fa-li fas fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email"><a href="mailto:fujian_whut@163.com">fujian_whut@163.com</a></span>
      </li>
      

      

      
      
        
        <li>
          <i class="fa-li fas fa-map-marker fa-2x" aria-hidden="true"></i>
          <span id="person-address">122 Luoshi Road, Wuhan, Hubei 430070</span>
        </li>
      

      

      

      

      
      

    </ul>

    

  </div>
</div>

    </div>
  </section>




      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    

    
    

    

    
    

    
    

    
    
    <script>
      if (window.netlifyIdentity) {
        window.netlifyIdentity.on("init", user => {
          if (!user) {
            window.netlifyIdentity.on("login", () => {
              document.location.href = "/admin/";
            });
          }
        });
      }
    </script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/wowchemy.min.eb5fcc96d414eaa162728694895a1ae2.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/en/privacy/"></a>
    
    
       &middot; 
      <a href="/en/terms/">Terms</a>
    
  </p>
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    
    Published with
    <a href="https://wowchemy.com" target="_blank" rel="noopener">Wowchemy</a>  —
    the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">
    open source</a> website builder that empowers creators.
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
